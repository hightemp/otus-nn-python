{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Домашнее задание 4\n",
    "Переобучение 1\n",
    "Добиться от классифкатора fashionminst переобучения \n",
    "за счет изменения архитектуры и гиперпараметров.\n",
    "Критерии оценки: По графикам ошибок и точности для \n",
    "тренировочного и тестового множества должно \n",
    "быть понятно, что переобучение наступило\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from utils import mnist\n",
    "import numpy as np\n",
    "\n",
    "from pprint import pprint "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, valid_loader, test_loader = mnist(valid=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, batchnorm=False, dropout=False, lr=1e-4, l2=0.):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 128)\n",
    "        self.fc2 = nn.Linear(128, 128)\n",
    "        self.fc3 = nn.Linear(128, 10)\n",
    "        if batchnorm:\n",
    "            self.bn = nn.BatchNorm1d(128)\n",
    "        self.batchnorm = batchnorm\n",
    "        \n",
    "        self.dropout = dropout\n",
    "        self.optim = optim.Adam(self.parameters(), lr=lr, weight_decay=l2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        x = torch.tanh(self.fc1(x))\n",
    "        if self.batchnorm:\n",
    "            x = self.bn(x)\n",
    "        x = torch.tanh(self.fc2(x))\n",
    "        if self.dropout:\n",
    "            x = F.dropout(x, 0.5)\n",
    "        x = self.fc3(x)\n",
    "        x = torch.log_softmax(x, dim=1)\n",
    "        return x\n",
    "    \n",
    "    def loss(self, output, target, **kwargs):\n",
    "        self._loss = F.nll_loss(output, target, **kwargs)\n",
    "        return self._loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, models):\n",
    "    train_size = len(train_loader.sampler)\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        for k, model in models.items():\n",
    "            model.optim.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = model.loss(output, target)\n",
    "            loss.backward()\n",
    "            model.optim.step()\n",
    "            \n",
    "        if batch_idx % 200 == 0:\n",
    "            line = 'Train Epoch: {} [{}/{} ({:.0f}%)]\\tLosses '.format(\n",
    "                epoch, batch_idx * len(data), train_size, 100. * batch_idx / len(train_loader))\n",
    "            losses = ' '.join(['{}: {:.6f}'.format(k, m._loss.item()) for k, m in models.items()])\n",
    "            print(line + losses)\n",
    "            \n",
    "    else:\n",
    "        batch_idx += 1\n",
    "        line = 'Train Epoch: {} [{}/{} ({:.0f}%)]\\tLosses '.format(\n",
    "            epoch, batch_idx * len(data), train_size, 100. * batch_idx / len(train_loader))\n",
    "        losses = ' '.join(['{}: {:.6f}'.format(k, m._loss.item()) for k, m in models.items()])\n",
    "        print(line + losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {'default': Net(True, False)} #, 'bn': Net(True, False), 'drop': Net(False, True), 'both': Net(True, True)}\n",
    "train_log = {k: [] for k in models}\n",
    "test_log = {k: [] for k in models}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(models, loader, log=None):\n",
    "    test_size = len(loader.sampler)\n",
    "    avg_lambda = lambda l: 'Loss: {:.4f}'.format(l)\n",
    "    acc_lambda = lambda c, p: 'Accuracy: {}/{} ({:.0f}%)'.format(c, test_size, p)\n",
    "    line = lambda i, l, c, p: '{}: '.format(i) + avg_lambda(l) + '\\t' + acc_lambda(c, p)\n",
    "\n",
    "    test_loss = {k: 0. for k in models}\n",
    "    correct = {k: 0. for k in models}\n",
    "    with torch.no_grad():\n",
    "        for data, target in loader:\n",
    "            # output = {k: m(data) for m in models}\n",
    "            for k, m in models.items():\n",
    "                output = m(data)\n",
    "                test_loss[k] += m.loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "                pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "                correct[k] += pred.eq(target.data.view_as(pred)).cpu().sum().item()\n",
    "    \n",
    "    for k in models:\n",
    "        test_loss[k] /= test_size\n",
    "    correct_pct = {k: 100. * correct[k] / test_size for k in correct}\n",
    "    lines = '\\n'.join([line(k, test_loss[k], correct[k], correct_pct[k]) for k in models]) + '\\n'\n",
    "    report = 'Test set:\\n' + lines\n",
    "    if log is not None:\n",
    "        for k in models:\n",
    "            log[k].append((test_loss[k], correct_pct[k]))\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/50000 (0%)]\tLosses default: 2.265755\n",
      "Train Epoch: 1 [10000/50000 (20%)]\tLosses default: 0.632516\n",
      "Train Epoch: 1 [20000/50000 (40%)]\tLosses default: 0.683979\n",
      "Train Epoch: 1 [30000/50000 (60%)]\tLosses default: 0.604496\n",
      "Train Epoch: 1 [40000/50000 (80%)]\tLosses default: 0.535571\n",
      "Train Epoch: 1 [50000/50000 (100%)]\tLosses default: 0.449007\n",
      "Test set:\n",
      "default: Loss: 0.4294\tAccuracy: 42553.0/50000 (85%)\n",
      "\n",
      "Test set:\n",
      "default: Loss: 0.4683\tAccuracy: 8349.0/10000 (83%)\n",
      "\n",
      "Train Epoch: 2 [0/50000 (0%)]\tLosses default: 0.541571\n",
      "Train Epoch: 2 [10000/50000 (20%)]\tLosses default: 0.323622\n",
      "Train Epoch: 2 [20000/50000 (40%)]\tLosses default: 0.316757\n",
      "Train Epoch: 2 [30000/50000 (60%)]\tLosses default: 0.304035\n",
      "Train Epoch: 2 [40000/50000 (80%)]\tLosses default: 0.458577\n",
      "Train Epoch: 2 [50000/50000 (100%)]\tLosses default: 0.439815\n",
      "Test set:\n",
      "default: Loss: 0.3606\tAccuracy: 43569.0/50000 (87%)\n",
      "\n",
      "Test set:\n",
      "default: Loss: 0.4109\tAccuracy: 8517.0/10000 (85%)\n",
      "\n",
      "Train Epoch: 3 [0/50000 (0%)]\tLosses default: 0.505944\n",
      "Train Epoch: 3 [10000/50000 (20%)]\tLosses default: 0.216126\n",
      "Train Epoch: 3 [20000/50000 (40%)]\tLosses default: 0.344389\n",
      "Train Epoch: 3 [30000/50000 (60%)]\tLosses default: 0.313280\n",
      "Train Epoch: 3 [40000/50000 (80%)]\tLosses default: 0.283825\n",
      "Train Epoch: 3 [50000/50000 (100%)]\tLosses default: 0.436058\n",
      "Test set:\n",
      "default: Loss: 0.3268\tAccuracy: 44230.0/50000 (88%)\n",
      "\n",
      "Test set:\n",
      "default: Loss: 0.3843\tAccuracy: 8633.0/10000 (86%)\n",
      "\n",
      "Train Epoch: 4 [0/50000 (0%)]\tLosses default: 0.290141\n",
      "Train Epoch: 4 [10000/50000 (20%)]\tLosses default: 0.425144\n",
      "Train Epoch: 4 [20000/50000 (40%)]\tLosses default: 0.375699\n",
      "Train Epoch: 4 [30000/50000 (60%)]\tLosses default: 0.430897\n",
      "Train Epoch: 4 [40000/50000 (80%)]\tLosses default: 0.486976\n",
      "Train Epoch: 4 [50000/50000 (100%)]\tLosses default: 0.291789\n",
      "Test set:\n",
      "default: Loss: 0.3038\tAccuracy: 44572.0/50000 (89%)\n",
      "\n",
      "Test set:\n",
      "default: Loss: 0.3672\tAccuracy: 8675.0/10000 (87%)\n",
      "\n",
      "Train Epoch: 5 [0/50000 (0%)]\tLosses default: 0.324837\n",
      "Train Epoch: 5 [10000/50000 (20%)]\tLosses default: 0.431514\n",
      "Train Epoch: 5 [20000/50000 (40%)]\tLosses default: 0.273812\n",
      "Train Epoch: 5 [30000/50000 (60%)]\tLosses default: 0.334921\n",
      "Train Epoch: 5 [40000/50000 (80%)]\tLosses default: 0.332580\n",
      "Train Epoch: 5 [50000/50000 (100%)]\tLosses default: 0.397246\n",
      "Test set:\n",
      "default: Loss: 0.2925\tAccuracy: 44781.0/50000 (90%)\n",
      "\n",
      "Test set:\n",
      "default: Loss: 0.3642\tAccuracy: 8676.0/10000 (87%)\n",
      "\n",
      "Train Epoch: 6 [0/50000 (0%)]\tLosses default: 0.404552\n",
      "Train Epoch: 6 [10000/50000 (20%)]\tLosses default: 0.277922\n",
      "Train Epoch: 6 [20000/50000 (40%)]\tLosses default: 0.272832\n",
      "Train Epoch: 6 [30000/50000 (60%)]\tLosses default: 0.422938\n",
      "Train Epoch: 6 [40000/50000 (80%)]\tLosses default: 0.460395\n",
      "Train Epoch: 6 [50000/50000 (100%)]\tLosses default: 0.291635\n",
      "Test set:\n",
      "default: Loss: 0.2900\tAccuracy: 44687.0/50000 (89%)\n",
      "\n",
      "Test set:\n",
      "default: Loss: 0.3679\tAccuracy: 8651.0/10000 (87%)\n",
      "\n",
      "Train Epoch: 7 [0/50000 (0%)]\tLosses default: 0.216872\n",
      "Train Epoch: 7 [10000/50000 (20%)]\tLosses default: 0.239795\n",
      "Train Epoch: 7 [20000/50000 (40%)]\tLosses default: 0.333118\n",
      "Train Epoch: 7 [30000/50000 (60%)]\tLosses default: 0.363479\n",
      "Train Epoch: 7 [40000/50000 (80%)]\tLosses default: 0.372846\n",
      "Train Epoch: 7 [50000/50000 (100%)]\tLosses default: 0.227425\n",
      "Test set:\n",
      "default: Loss: 0.2633\tAccuracy: 45262.0/50000 (91%)\n",
      "\n",
      "Test set:\n",
      "default: Loss: 0.3464\tAccuracy: 8772.0/10000 (88%)\n",
      "\n",
      "Train Epoch: 8 [0/50000 (0%)]\tLosses default: 0.248299\n",
      "Train Epoch: 8 [10000/50000 (20%)]\tLosses default: 0.245808\n",
      "Train Epoch: 8 [20000/50000 (40%)]\tLosses default: 0.234221\n",
      "Train Epoch: 8 [30000/50000 (60%)]\tLosses default: 0.221221\n",
      "Train Epoch: 8 [40000/50000 (80%)]\tLosses default: 0.298724\n",
      "Train Epoch: 8 [50000/50000 (100%)]\tLosses default: 0.299841\n",
      "Test set:\n",
      "default: Loss: 0.2522\tAccuracy: 45510.0/50000 (91%)\n",
      "\n",
      "Test set:\n",
      "default: Loss: 0.3419\tAccuracy: 8732.0/10000 (87%)\n",
      "\n",
      "Train Epoch: 9 [0/50000 (0%)]\tLosses default: 0.237660\n",
      "Train Epoch: 9 [10000/50000 (20%)]\tLosses default: 0.232903\n",
      "Train Epoch: 9 [20000/50000 (40%)]\tLosses default: 0.141598\n",
      "Train Epoch: 9 [30000/50000 (60%)]\tLosses default: 0.252989\n",
      "Train Epoch: 9 [40000/50000 (80%)]\tLosses default: 0.292452\n",
      "Train Epoch: 9 [50000/50000 (100%)]\tLosses default: 0.342780\n",
      "Test set:\n",
      "default: Loss: 0.2399\tAccuracy: 45651.0/50000 (91%)\n",
      "\n",
      "Test set:\n",
      "default: Loss: 0.3378\tAccuracy: 8784.0/10000 (88%)\n",
      "\n",
      "Train Epoch: 10 [0/50000 (0%)]\tLosses default: 0.134143\n",
      "Train Epoch: 10 [10000/50000 (20%)]\tLosses default: 0.225884\n",
      "Train Epoch: 10 [20000/50000 (40%)]\tLosses default: 0.186580\n",
      "Train Epoch: 10 [30000/50000 (60%)]\tLosses default: 0.254104\n",
      "Train Epoch: 10 [40000/50000 (80%)]\tLosses default: 0.089798\n",
      "Train Epoch: 10 [50000/50000 (100%)]\tLosses default: 0.143612\n",
      "Test set:\n",
      "default: Loss: 0.2358\tAccuracy: 45690.0/50000 (91%)\n",
      "\n",
      "Test set:\n",
      "default: Loss: 0.3381\tAccuracy: 8769.0/10000 (88%)\n",
      "\n",
      "Train Epoch: 11 [0/50000 (0%)]\tLosses default: 0.183114\n",
      "Train Epoch: 11 [10000/50000 (20%)]\tLosses default: 0.270196\n",
      "Train Epoch: 11 [20000/50000 (40%)]\tLosses default: 0.424233\n",
      "Train Epoch: 11 [30000/50000 (60%)]\tLosses default: 0.313869\n",
      "Train Epoch: 11 [40000/50000 (80%)]\tLosses default: 0.172240\n",
      "Train Epoch: 11 [50000/50000 (100%)]\tLosses default: 0.417882\n",
      "Test set:\n",
      "default: Loss: 0.2342\tAccuracy: 45683.0/50000 (91%)\n",
      "\n",
      "Test set:\n",
      "default: Loss: 0.3415\tAccuracy: 8746.0/10000 (87%)\n",
      "\n",
      "Train Epoch: 12 [0/50000 (0%)]\tLosses default: 0.195717\n",
      "Train Epoch: 12 [10000/50000 (20%)]\tLosses default: 0.173808\n",
      "Train Epoch: 12 [20000/50000 (40%)]\tLosses default: 0.388262\n",
      "Train Epoch: 12 [30000/50000 (60%)]\tLosses default: 0.252818\n",
      "Train Epoch: 12 [40000/50000 (80%)]\tLosses default: 0.357547\n",
      "Train Epoch: 12 [50000/50000 (100%)]\tLosses default: 0.186629\n",
      "Test set:\n",
      "default: Loss: 0.2113\tAccuracy: 46216.0/50000 (92%)\n",
      "\n",
      "Test set:\n",
      "default: Loss: 0.3284\tAccuracy: 8793.0/10000 (88%)\n",
      "\n",
      "Train Epoch: 13 [0/50000 (0%)]\tLosses default: 0.294896\n",
      "Train Epoch: 13 [10000/50000 (20%)]\tLosses default: 0.242698\n",
      "Train Epoch: 13 [20000/50000 (40%)]\tLosses default: 0.274550\n",
      "Train Epoch: 13 [30000/50000 (60%)]\tLosses default: 0.282466\n",
      "Train Epoch: 13 [40000/50000 (80%)]\tLosses default: 0.231500\n",
      "Train Epoch: 13 [50000/50000 (100%)]\tLosses default: 0.342384\n",
      "Test set:\n",
      "default: Loss: 0.2017\tAccuracy: 46444.0/50000 (93%)\n",
      "\n",
      "Test set:\n",
      "default: Loss: 0.3249\tAccuracy: 8809.0/10000 (88%)\n",
      "\n",
      "Train Epoch: 14 [0/50000 (0%)]\tLosses default: 0.271123\n",
      "Train Epoch: 14 [10000/50000 (20%)]\tLosses default: 0.066941\n",
      "Train Epoch: 14 [20000/50000 (40%)]\tLosses default: 0.139399\n",
      "Train Epoch: 14 [30000/50000 (60%)]\tLosses default: 0.118738\n",
      "Train Epoch: 14 [40000/50000 (80%)]\tLosses default: 0.218861\n",
      "Train Epoch: 14 [50000/50000 (100%)]\tLosses default: 0.207219\n",
      "Test set:\n",
      "default: Loss: 0.2016\tAccuracy: 46400.0/50000 (93%)\n",
      "\n",
      "Test set:\n",
      "default: Loss: 0.3318\tAccuracy: 8818.0/10000 (88%)\n",
      "\n",
      "Train Epoch: 15 [0/50000 (0%)]\tLosses default: 0.378111\n",
      "Train Epoch: 15 [10000/50000 (20%)]\tLosses default: 0.111995\n",
      "Train Epoch: 15 [20000/50000 (40%)]\tLosses default: 0.275391\n",
      "Train Epoch: 15 [30000/50000 (60%)]\tLosses default: 0.215156\n",
      "Train Epoch: 15 [40000/50000 (80%)]\tLosses default: 0.340973\n",
      "Train Epoch: 15 [50000/50000 (100%)]\tLosses default: 0.350234\n",
      "Test set:\n",
      "default: Loss: 0.1886\tAccuracy: 46666.0/50000 (93%)\n",
      "\n",
      "Test set:\n",
      "default: Loss: 0.3235\tAccuracy: 8843.0/10000 (88%)\n",
      "\n",
      "Train Epoch: 16 [0/50000 (0%)]\tLosses default: 0.204573\n",
      "Train Epoch: 16 [10000/50000 (20%)]\tLosses default: 0.140507\n",
      "Train Epoch: 16 [20000/50000 (40%)]\tLosses default: 0.178479\n",
      "Train Epoch: 16 [30000/50000 (60%)]\tLosses default: 0.217756\n",
      "Train Epoch: 16 [40000/50000 (80%)]\tLosses default: 0.216353\n",
      "Train Epoch: 16 [50000/50000 (100%)]\tLosses default: 0.260673\n",
      "Test set:\n",
      "default: Loss: 0.1844\tAccuracy: 46631.0/50000 (93%)\n",
      "\n",
      "Test set:\n",
      "default: Loss: 0.3265\tAccuracy: 8838.0/10000 (88%)\n",
      "\n",
      "Train Epoch: 17 [0/50000 (0%)]\tLosses default: 0.082115\n",
      "Train Epoch: 17 [10000/50000 (20%)]\tLosses default: 0.282244\n",
      "Train Epoch: 17 [20000/50000 (40%)]\tLosses default: 0.166057\n",
      "Train Epoch: 17 [30000/50000 (60%)]\tLosses default: 0.237505\n",
      "Train Epoch: 17 [40000/50000 (80%)]\tLosses default: 0.163449\n",
      "Train Epoch: 17 [50000/50000 (100%)]\tLosses default: 0.194267\n",
      "Test set:\n",
      "default: Loss: 0.1787\tAccuracy: 46783.0/50000 (94%)\n",
      "\n",
      "Test set:\n",
      "default: Loss: 0.3268\tAccuracy: 8860.0/10000 (89%)\n",
      "\n",
      "Train Epoch: 18 [0/50000 (0%)]\tLosses default: 0.075295\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 18 [10000/50000 (20%)]\tLosses default: 0.229578\n",
      "Train Epoch: 18 [20000/50000 (40%)]\tLosses default: 0.094369\n",
      "Train Epoch: 18 [30000/50000 (60%)]\tLosses default: 0.287151\n",
      "Train Epoch: 18 [40000/50000 (80%)]\tLosses default: 0.193768\n",
      "Train Epoch: 18 [50000/50000 (100%)]\tLosses default: 0.225519\n",
      "Test set:\n",
      "default: Loss: 0.1777\tAccuracy: 46846.0/50000 (94%)\n",
      "\n",
      "Test set:\n",
      "default: Loss: 0.3345\tAccuracy: 8838.0/10000 (88%)\n",
      "\n",
      "Train Epoch: 19 [0/50000 (0%)]\tLosses default: 0.192334\n",
      "Train Epoch: 19 [10000/50000 (20%)]\tLosses default: 0.158338\n",
      "Train Epoch: 19 [20000/50000 (40%)]\tLosses default: 0.243263\n",
      "Train Epoch: 19 [30000/50000 (60%)]\tLosses default: 0.245246\n",
      "Train Epoch: 19 [40000/50000 (80%)]\tLosses default: 0.207999\n",
      "Train Epoch: 19 [50000/50000 (100%)]\tLosses default: 0.197115\n",
      "Test set:\n",
      "default: Loss: 0.1672\tAccuracy: 47073.0/50000 (94%)\n",
      "\n",
      "Test set:\n",
      "default: Loss: 0.3262\tAccuracy: 8852.0/10000 (89%)\n",
      "\n",
      "Train Epoch: 20 [0/50000 (0%)]\tLosses default: 0.194593\n",
      "Train Epoch: 20 [10000/50000 (20%)]\tLosses default: 0.131133\n",
      "Train Epoch: 20 [20000/50000 (40%)]\tLosses default: 0.254772\n",
      "Train Epoch: 20 [30000/50000 (60%)]\tLosses default: 0.094105\n",
      "Train Epoch: 20 [40000/50000 (80%)]\tLosses default: 0.150752\n",
      "Train Epoch: 20 [50000/50000 (100%)]\tLosses default: 0.139728\n",
      "Test set:\n",
      "default: Loss: 0.1695\tAccuracy: 46953.0/50000 (94%)\n",
      "\n",
      "Test set:\n",
      "default: Loss: 0.3386\tAccuracy: 8821.0/10000 (88%)\n",
      "\n",
      "Train Epoch: 21 [0/50000 (0%)]\tLosses default: 0.265709\n",
      "Train Epoch: 21 [10000/50000 (20%)]\tLosses default: 0.152893\n",
      "Train Epoch: 21 [20000/50000 (40%)]\tLosses default: 0.115538\n",
      "Train Epoch: 21 [30000/50000 (60%)]\tLosses default: 0.177613\n",
      "Train Epoch: 21 [40000/50000 (80%)]\tLosses default: 0.219216\n",
      "Train Epoch: 21 [50000/50000 (100%)]\tLosses default: 0.094117\n",
      "Test set:\n",
      "default: Loss: 0.1571\tAccuracy: 47180.0/50000 (94%)\n",
      "\n",
      "Test set:\n",
      "default: Loss: 0.3318\tAccuracy: 8838.0/10000 (88%)\n",
      "\n",
      "Train Epoch: 22 [0/50000 (0%)]\tLosses default: 0.154393\n",
      "Train Epoch: 22 [10000/50000 (20%)]\tLosses default: 0.089063\n",
      "Train Epoch: 22 [20000/50000 (40%)]\tLosses default: 0.100910\n",
      "Train Epoch: 22 [30000/50000 (60%)]\tLosses default: 0.097824\n",
      "Train Epoch: 22 [40000/50000 (80%)]\tLosses default: 0.085176\n",
      "Train Epoch: 22 [50000/50000 (100%)]\tLosses default: 0.139004\n",
      "Test set:\n",
      "default: Loss: 0.1517\tAccuracy: 47371.0/50000 (95%)\n",
      "\n",
      "Test set:\n",
      "default: Loss: 0.3278\tAccuracy: 8877.0/10000 (89%)\n",
      "\n",
      "Train Epoch: 23 [0/50000 (0%)]\tLosses default: 0.068858\n",
      "Train Epoch: 23 [10000/50000 (20%)]\tLosses default: 0.179831\n",
      "Train Epoch: 23 [20000/50000 (40%)]\tLosses default: 0.153628\n",
      "Train Epoch: 23 [30000/50000 (60%)]\tLosses default: 0.120398\n",
      "Train Epoch: 23 [40000/50000 (80%)]\tLosses default: 0.150392\n",
      "Train Epoch: 23 [50000/50000 (100%)]\tLosses default: 0.102737\n",
      "Test set:\n",
      "default: Loss: 0.1484\tAccuracy: 47403.0/50000 (95%)\n",
      "\n",
      "Test set:\n",
      "default: Loss: 0.3323\tAccuracy: 8847.0/10000 (88%)\n",
      "\n",
      "Train Epoch: 24 [0/50000 (0%)]\tLosses default: 0.232717\n",
      "Train Epoch: 24 [10000/50000 (20%)]\tLosses default: 0.120858\n",
      "Train Epoch: 24 [20000/50000 (40%)]\tLosses default: 0.107672\n",
      "Train Epoch: 24 [30000/50000 (60%)]\tLosses default: 0.288787\n",
      "Train Epoch: 24 [40000/50000 (80%)]\tLosses default: 0.328918\n",
      "Train Epoch: 24 [50000/50000 (100%)]\tLosses default: 0.213490\n",
      "Test set:\n",
      "default: Loss: 0.1474\tAccuracy: 47340.0/50000 (95%)\n",
      "\n",
      "Test set:\n",
      "default: Loss: 0.3357\tAccuracy: 8819.0/10000 (88%)\n",
      "\n",
      "Train Epoch: 25 [0/50000 (0%)]\tLosses default: 0.194026\n",
      "Train Epoch: 25 [10000/50000 (20%)]\tLosses default: 0.105384\n",
      "Train Epoch: 25 [20000/50000 (40%)]\tLosses default: 0.205752\n",
      "Train Epoch: 25 [30000/50000 (60%)]\tLosses default: 0.138317\n",
      "Train Epoch: 25 [40000/50000 (80%)]\tLosses default: 0.167640\n",
      "Train Epoch: 25 [50000/50000 (100%)]\tLosses default: 0.070974\n",
      "Test set:\n",
      "default: Loss: 0.1355\tAccuracy: 47639.0/50000 (95%)\n",
      "\n",
      "Test set:\n",
      "default: Loss: 0.3313\tAccuracy: 8859.0/10000 (89%)\n",
      "\n",
      "Train Epoch: 26 [0/50000 (0%)]\tLosses default: 0.111039\n",
      "Train Epoch: 26 [10000/50000 (20%)]\tLosses default: 0.100845\n",
      "Train Epoch: 26 [20000/50000 (40%)]\tLosses default: 0.059970\n",
      "Train Epoch: 26 [30000/50000 (60%)]\tLosses default: 0.108209\n",
      "Train Epoch: 26 [40000/50000 (80%)]\tLosses default: 0.315123\n",
      "Train Epoch: 26 [50000/50000 (100%)]\tLosses default: 0.212492\n",
      "Test set:\n",
      "default: Loss: 0.1372\tAccuracy: 47521.0/50000 (95%)\n",
      "\n",
      "Test set:\n",
      "default: Loss: 0.3373\tAccuracy: 8877.0/10000 (89%)\n",
      "\n",
      "Train Epoch: 27 [0/50000 (0%)]\tLosses default: 0.102545\n",
      "Train Epoch: 27 [10000/50000 (20%)]\tLosses default: 0.204413\n",
      "Train Epoch: 27 [20000/50000 (40%)]\tLosses default: 0.323985\n",
      "Train Epoch: 27 [30000/50000 (60%)]\tLosses default: 0.083651\n",
      "Train Epoch: 27 [40000/50000 (80%)]\tLosses default: 0.150522\n",
      "Train Epoch: 27 [50000/50000 (100%)]\tLosses default: 0.065141\n",
      "Test set:\n",
      "default: Loss: 0.1275\tAccuracy: 47794.0/50000 (96%)\n",
      "\n",
      "Test set:\n",
      "default: Loss: 0.3325\tAccuracy: 8896.0/10000 (89%)\n",
      "\n",
      "Train Epoch: 28 [0/50000 (0%)]\tLosses default: 0.159535\n",
      "Train Epoch: 28 [10000/50000 (20%)]\tLosses default: 0.247597\n",
      "Train Epoch: 28 [20000/50000 (40%)]\tLosses default: 0.223628\n",
      "Train Epoch: 28 [30000/50000 (60%)]\tLosses default: 0.236349\n",
      "Train Epoch: 28 [40000/50000 (80%)]\tLosses default: 0.166318\n",
      "Train Epoch: 28 [50000/50000 (100%)]\tLosses default: 0.056561\n",
      "Test set:\n",
      "default: Loss: 0.1272\tAccuracy: 47798.0/50000 (96%)\n",
      "\n",
      "Test set:\n",
      "default: Loss: 0.3395\tAccuracy: 8848.0/10000 (88%)\n",
      "\n",
      "Train Epoch: 29 [0/50000 (0%)]\tLosses default: 0.069596\n",
      "Train Epoch: 29 [10000/50000 (20%)]\tLosses default: 0.135327\n",
      "Train Epoch: 29 [20000/50000 (40%)]\tLosses default: 0.133668\n",
      "Train Epoch: 29 [30000/50000 (60%)]\tLosses default: 0.117134\n",
      "Train Epoch: 29 [40000/50000 (80%)]\tLosses default: 0.070069\n",
      "Train Epoch: 29 [50000/50000 (100%)]\tLosses default: 0.073257\n",
      "Test set:\n",
      "default: Loss: 0.1257\tAccuracy: 47753.0/50000 (96%)\n",
      "\n",
      "Test set:\n",
      "default: Loss: 0.3404\tAccuracy: 8863.0/10000 (89%)\n",
      "\n",
      "Train Epoch: 30 [0/50000 (0%)]\tLosses default: 0.073468\n",
      "Train Epoch: 30 [10000/50000 (20%)]\tLosses default: 0.166055\n",
      "Train Epoch: 30 [20000/50000 (40%)]\tLosses default: 0.132413\n",
      "Train Epoch: 30 [30000/50000 (60%)]\tLosses default: 0.070111\n",
      "Train Epoch: 30 [40000/50000 (80%)]\tLosses default: 0.398044\n",
      "Train Epoch: 30 [50000/50000 (100%)]\tLosses default: 0.280118\n",
      "Test set:\n",
      "default: Loss: 0.1167\tAccuracy: 47954.0/50000 (96%)\n",
      "\n",
      "Test set:\n",
      "default: Loss: 0.3425\tAccuracy: 8872.0/10000 (89%)\n",
      "\n",
      "Train Epoch: 31 [0/50000 (0%)]\tLosses default: 0.092216\n",
      "Train Epoch: 31 [10000/50000 (20%)]\tLosses default: 0.282219\n",
      "Train Epoch: 31 [20000/50000 (40%)]\tLosses default: 0.139229\n",
      "Train Epoch: 31 [30000/50000 (60%)]\tLosses default: 0.140399\n",
      "Train Epoch: 31 [40000/50000 (80%)]\tLosses default: 0.073022\n",
      "Train Epoch: 31 [50000/50000 (100%)]\tLosses default: 0.190393\n",
      "Test set:\n",
      "default: Loss: 0.1134\tAccuracy: 48077.0/50000 (96%)\n",
      "\n",
      "Test set:\n",
      "default: Loss: 0.3459\tAccuracy: 8859.0/10000 (89%)\n",
      "\n",
      "Train Epoch: 32 [0/50000 (0%)]\tLosses default: 0.113364\n",
      "Train Epoch: 32 [10000/50000 (20%)]\tLosses default: 0.146754\n",
      "Train Epoch: 32 [20000/50000 (40%)]\tLosses default: 0.063183\n",
      "Train Epoch: 32 [30000/50000 (60%)]\tLosses default: 0.113917\n",
      "Train Epoch: 32 [40000/50000 (80%)]\tLosses default: 0.118675\n",
      "Train Epoch: 32 [50000/50000 (100%)]\tLosses default: 0.038233\n",
      "Test set:\n",
      "default: Loss: 0.1288\tAccuracy: 47690.0/50000 (95%)\n",
      "\n",
      "Test set:\n",
      "default: Loss: 0.3633\tAccuracy: 8829.0/10000 (88%)\n",
      "\n",
      "Train Epoch: 33 [0/50000 (0%)]\tLosses default: 0.118500\n",
      "Train Epoch: 33 [10000/50000 (20%)]\tLosses default: 0.104046\n",
      "Train Epoch: 33 [20000/50000 (40%)]\tLosses default: 0.055056\n",
      "Train Epoch: 33 [30000/50000 (60%)]\tLosses default: 0.043519\n",
      "Train Epoch: 33 [40000/50000 (80%)]\tLosses default: 0.072622\n",
      "Train Epoch: 33 [50000/50000 (100%)]\tLosses default: 0.045507\n",
      "Test set:\n",
      "default: Loss: 0.1095\tAccuracy: 48101.0/50000 (96%)\n",
      "\n",
      "Test set:\n",
      "default: Loss: 0.3487\tAccuracy: 8884.0/10000 (89%)\n",
      "\n",
      "Train Epoch: 34 [0/50000 (0%)]\tLosses default: 0.231149\n",
      "Train Epoch: 34 [10000/50000 (20%)]\tLosses default: 0.047109\n",
      "Train Epoch: 34 [20000/50000 (40%)]\tLosses default: 0.053233\n",
      "Train Epoch: 34 [30000/50000 (60%)]\tLosses default: 0.184419\n",
      "Train Epoch: 34 [40000/50000 (80%)]\tLosses default: 0.096295\n",
      "Train Epoch: 34 [50000/50000 (100%)]\tLosses default: 0.141070\n",
      "Test set:\n",
      "default: Loss: 0.1043\tAccuracy: 48202.0/50000 (96%)\n",
      "\n",
      "Test set:\n",
      "default: Loss: 0.3442\tAccuracy: 8890.0/10000 (89%)\n",
      "\n",
      "Train Epoch: 35 [0/50000 (0%)]\tLosses default: 0.135594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 35 [10000/50000 (20%)]\tLosses default: 0.254744\n",
      "Train Epoch: 35 [20000/50000 (40%)]\tLosses default: 0.068431\n",
      "Train Epoch: 35 [30000/50000 (60%)]\tLosses default: 0.141713\n",
      "Train Epoch: 35 [40000/50000 (80%)]\tLosses default: 0.163739\n",
      "Train Epoch: 35 [50000/50000 (100%)]\tLosses default: 0.077188\n",
      "Test set:\n",
      "default: Loss: 0.1038\tAccuracy: 48182.0/50000 (96%)\n",
      "\n",
      "Test set:\n",
      "default: Loss: 0.3550\tAccuracy: 8849.0/10000 (88%)\n",
      "\n",
      "Train Epoch: 36 [0/50000 (0%)]\tLosses default: 0.104363\n",
      "Train Epoch: 36 [10000/50000 (20%)]\tLosses default: 0.096280\n",
      "Train Epoch: 36 [20000/50000 (40%)]\tLosses default: 0.036175\n",
      "Train Epoch: 36 [30000/50000 (60%)]\tLosses default: 0.148645\n",
      "Train Epoch: 36 [40000/50000 (80%)]\tLosses default: 0.088787\n",
      "Train Epoch: 36 [50000/50000 (100%)]\tLosses default: 0.164260\n",
      "Test set:\n",
      "default: Loss: 0.0950\tAccuracy: 48408.0/50000 (97%)\n",
      "\n",
      "Test set:\n",
      "default: Loss: 0.3535\tAccuracy: 8889.0/10000 (89%)\n",
      "\n",
      "Train Epoch: 37 [0/50000 (0%)]\tLosses default: 0.185965\n",
      "Train Epoch: 37 [10000/50000 (20%)]\tLosses default: 0.074060\n",
      "Train Epoch: 37 [20000/50000 (40%)]\tLosses default: 0.113367\n",
      "Train Epoch: 37 [30000/50000 (60%)]\tLosses default: 0.110207\n",
      "Train Epoch: 37 [40000/50000 (80%)]\tLosses default: 0.086126\n",
      "Train Epoch: 37 [50000/50000 (100%)]\tLosses default: 0.121692\n",
      "Test set:\n",
      "default: Loss: 0.0984\tAccuracy: 48328.0/50000 (97%)\n",
      "\n",
      "Test set:\n",
      "default: Loss: 0.3608\tAccuracy: 8859.0/10000 (89%)\n",
      "\n",
      "Train Epoch: 38 [0/50000 (0%)]\tLosses default: 0.034273\n",
      "Train Epoch: 38 [10000/50000 (20%)]\tLosses default: 0.040972\n",
      "Train Epoch: 38 [20000/50000 (40%)]\tLosses default: 0.055615\n",
      "Train Epoch: 38 [30000/50000 (60%)]\tLosses default: 0.141454\n",
      "Train Epoch: 38 [40000/50000 (80%)]\tLosses default: 0.106776\n",
      "Train Epoch: 38 [50000/50000 (100%)]\tLosses default: 0.110164\n",
      "Test set:\n",
      "default: Loss: 0.0931\tAccuracy: 48419.0/50000 (97%)\n",
      "\n",
      "Test set:\n",
      "default: Loss: 0.3594\tAccuracy: 8857.0/10000 (89%)\n",
      "\n",
      "Train Epoch: 39 [0/50000 (0%)]\tLosses default: 0.062159\n",
      "Train Epoch: 39 [10000/50000 (20%)]\tLosses default: 0.097868\n",
      "Train Epoch: 39 [20000/50000 (40%)]\tLosses default: 0.119751\n",
      "Train Epoch: 39 [30000/50000 (60%)]\tLosses default: 0.092388\n",
      "Train Epoch: 39 [40000/50000 (80%)]\tLosses default: 0.119216\n",
      "Train Epoch: 39 [50000/50000 (100%)]\tLosses default: 0.124112\n",
      "Test set:\n",
      "default: Loss: 0.0902\tAccuracy: 48431.0/50000 (97%)\n",
      "\n",
      "Test set:\n",
      "default: Loss: 0.3639\tAccuracy: 8850.0/10000 (88%)\n",
      "\n",
      "Train Epoch: 40 [0/50000 (0%)]\tLosses default: 0.117327\n",
      "Train Epoch: 40 [10000/50000 (20%)]\tLosses default: 0.040191\n",
      "Train Epoch: 40 [20000/50000 (40%)]\tLosses default: 0.157295\n",
      "Train Epoch: 40 [30000/50000 (60%)]\tLosses default: 0.049159\n",
      "Train Epoch: 40 [40000/50000 (80%)]\tLosses default: 0.269429\n",
      "Train Epoch: 40 [50000/50000 (100%)]\tLosses default: 0.173390\n",
      "Test set:\n",
      "default: Loss: 0.0880\tAccuracy: 48521.0/50000 (97%)\n",
      "\n",
      "Test set:\n",
      "default: Loss: 0.3698\tAccuracy: 8864.0/10000 (89%)\n",
      "\n",
      "Train Epoch: 41 [0/50000 (0%)]\tLosses default: 0.137887\n",
      "Train Epoch: 41 [10000/50000 (20%)]\tLosses default: 0.171634\n",
      "Train Epoch: 41 [20000/50000 (40%)]\tLosses default: 0.041128\n",
      "Train Epoch: 41 [30000/50000 (60%)]\tLosses default: 0.196991\n",
      "Train Epoch: 41 [40000/50000 (80%)]\tLosses default: 0.019858\n",
      "Train Epoch: 41 [50000/50000 (100%)]\tLosses default: 0.161549\n",
      "Test set:\n",
      "default: Loss: 0.0836\tAccuracy: 48598.0/50000 (97%)\n",
      "\n",
      "Test set:\n",
      "default: Loss: 0.3753\tAccuracy: 8870.0/10000 (89%)\n",
      "\n",
      "Train Epoch: 42 [0/50000 (0%)]\tLosses default: 0.176213\n",
      "Train Epoch: 42 [10000/50000 (20%)]\tLosses default: 0.061587\n",
      "Train Epoch: 42 [20000/50000 (40%)]\tLosses default: 0.097043\n",
      "Train Epoch: 42 [30000/50000 (60%)]\tLosses default: 0.135498\n",
      "Train Epoch: 42 [40000/50000 (80%)]\tLosses default: 0.141079\n",
      "Train Epoch: 42 [50000/50000 (100%)]\tLosses default: 0.137071\n",
      "Test set:\n",
      "default: Loss: 0.0832\tAccuracy: 48546.0/50000 (97%)\n",
      "\n",
      "Test set:\n",
      "default: Loss: 0.3745\tAccuracy: 8863.0/10000 (89%)\n",
      "\n",
      "Train Epoch: 43 [0/50000 (0%)]\tLosses default: 0.093327\n",
      "Train Epoch: 43 [10000/50000 (20%)]\tLosses default: 0.148145\n",
      "Train Epoch: 43 [20000/50000 (40%)]\tLosses default: 0.126978\n",
      "Train Epoch: 43 [30000/50000 (60%)]\tLosses default: 0.048711\n",
      "Train Epoch: 43 [40000/50000 (80%)]\tLosses default: 0.060410\n",
      "Train Epoch: 43 [50000/50000 (100%)]\tLosses default: 0.171093\n",
      "Test set:\n",
      "default: Loss: 0.0810\tAccuracy: 48655.0/50000 (97%)\n",
      "\n",
      "Test set:\n",
      "default: Loss: 0.3743\tAccuracy: 8876.0/10000 (89%)\n",
      "\n",
      "Train Epoch: 44 [0/50000 (0%)]\tLosses default: 0.019727\n",
      "Train Epoch: 44 [10000/50000 (20%)]\tLosses default: 0.093655\n",
      "Train Epoch: 44 [20000/50000 (40%)]\tLosses default: 0.104522\n",
      "Train Epoch: 44 [30000/50000 (60%)]\tLosses default: 0.050367\n",
      "Train Epoch: 44 [40000/50000 (80%)]\tLosses default: 0.077207\n",
      "Train Epoch: 44 [50000/50000 (100%)]\tLosses default: 0.107529\n",
      "Test set:\n",
      "default: Loss: 0.0716\tAccuracy: 48851.0/50000 (98%)\n",
      "\n",
      "Test set:\n",
      "default: Loss: 0.3747\tAccuracy: 8889.0/10000 (89%)\n",
      "\n",
      "Train Epoch: 45 [0/50000 (0%)]\tLosses default: 0.034945\n",
      "Train Epoch: 45 [10000/50000 (20%)]\tLosses default: 0.070871\n",
      "Train Epoch: 45 [20000/50000 (40%)]\tLosses default: 0.107979\n",
      "Train Epoch: 45 [30000/50000 (60%)]\tLosses default: 0.210612\n",
      "Train Epoch: 45 [40000/50000 (80%)]\tLosses default: 0.134458\n",
      "Train Epoch: 45 [50000/50000 (100%)]\tLosses default: 0.108513\n",
      "Test set:\n",
      "default: Loss: 0.0788\tAccuracy: 48684.0/50000 (97%)\n",
      "\n",
      "Test set:\n",
      "default: Loss: 0.3788\tAccuracy: 8877.0/10000 (89%)\n",
      "\n",
      "Train Epoch: 46 [0/50000 (0%)]\tLosses default: 0.039304\n",
      "Train Epoch: 46 [10000/50000 (20%)]\tLosses default: 0.065045\n",
      "Train Epoch: 46 [20000/50000 (40%)]\tLosses default: 0.108147\n",
      "Train Epoch: 46 [30000/50000 (60%)]\tLosses default: 0.062249\n",
      "Train Epoch: 46 [40000/50000 (80%)]\tLosses default: 0.014437\n",
      "Train Epoch: 46 [50000/50000 (100%)]\tLosses default: 0.089259\n",
      "Test set:\n",
      "default: Loss: 0.0709\tAccuracy: 48846.0/50000 (98%)\n",
      "\n",
      "Test set:\n",
      "default: Loss: 0.3762\tAccuracy: 8903.0/10000 (89%)\n",
      "\n",
      "Train Epoch: 47 [0/50000 (0%)]\tLosses default: 0.027826\n",
      "Train Epoch: 47 [10000/50000 (20%)]\tLosses default: 0.065934\n",
      "Train Epoch: 47 [20000/50000 (40%)]\tLosses default: 0.055280\n",
      "Train Epoch: 47 [30000/50000 (60%)]\tLosses default: 0.032316\n",
      "Train Epoch: 47 [40000/50000 (80%)]\tLosses default: 0.148110\n",
      "Train Epoch: 47 [50000/50000 (100%)]\tLosses default: 0.230474\n",
      "Test set:\n",
      "default: Loss: 0.0677\tAccuracy: 48925.0/50000 (98%)\n",
      "\n",
      "Test set:\n",
      "default: Loss: 0.3825\tAccuracy: 8892.0/10000 (89%)\n",
      "\n",
      "Train Epoch: 48 [0/50000 (0%)]\tLosses default: 0.077546\n",
      "Train Epoch: 48 [10000/50000 (20%)]\tLosses default: 0.143561\n",
      "Train Epoch: 48 [20000/50000 (40%)]\tLosses default: 0.144890\n",
      "Train Epoch: 48 [30000/50000 (60%)]\tLosses default: 0.171532\n",
      "Train Epoch: 48 [40000/50000 (80%)]\tLosses default: 0.194358\n",
      "Train Epoch: 48 [50000/50000 (100%)]\tLosses default: 0.040327\n",
      "Test set:\n",
      "default: Loss: 0.0796\tAccuracy: 48588.0/50000 (97%)\n",
      "\n",
      "Test set:\n",
      "default: Loss: 0.4032\tAccuracy: 8876.0/10000 (89%)\n",
      "\n",
      "Train Epoch: 49 [0/50000 (0%)]\tLosses default: 0.122980\n",
      "Train Epoch: 49 [10000/50000 (20%)]\tLosses default: 0.067977\n",
      "Train Epoch: 49 [20000/50000 (40%)]\tLosses default: 0.133109\n",
      "Train Epoch: 49 [30000/50000 (60%)]\tLosses default: 0.036856\n",
      "Train Epoch: 49 [40000/50000 (80%)]\tLosses default: 0.079384\n",
      "Train Epoch: 49 [50000/50000 (100%)]\tLosses default: 0.149167\n",
      "Test set:\n",
      "default: Loss: 0.0666\tAccuracy: 48862.0/50000 (98%)\n",
      "\n",
      "Test set:\n",
      "default: Loss: 0.3944\tAccuracy: 8882.0/10000 (89%)\n",
      "\n",
      "Train Epoch: 50 [0/50000 (0%)]\tLosses default: 0.062470\n",
      "Train Epoch: 50 [10000/50000 (20%)]\tLosses default: 0.035000\n",
      "Train Epoch: 50 [20000/50000 (40%)]\tLosses default: 0.087378\n",
      "Train Epoch: 50 [30000/50000 (60%)]\tLosses default: 0.055750\n",
      "Train Epoch: 50 [40000/50000 (80%)]\tLosses default: 0.021851\n",
      "Train Epoch: 50 [50000/50000 (100%)]\tLosses default: 0.055365\n",
      "Test set:\n",
      "default: Loss: 0.0751\tAccuracy: 48667.0/50000 (97%)\n",
      "\n",
      "Test set:\n",
      "default: Loss: 0.4019\tAccuracy: 8861.0/10000 (89%)\n",
      "\n",
      "Train Epoch: 51 [0/50000 (0%)]\tLosses default: 0.057195\n",
      "Train Epoch: 51 [10000/50000 (20%)]\tLosses default: 0.047604\n",
      "Train Epoch: 51 [20000/50000 (40%)]\tLosses default: 0.040069\n",
      "Train Epoch: 51 [30000/50000 (60%)]\tLosses default: 0.206853\n",
      "Train Epoch: 51 [40000/50000 (80%)]\tLosses default: 0.067762\n",
      "Train Epoch: 51 [50000/50000 (100%)]\tLosses default: 0.054840\n",
      "Test set:\n",
      "default: Loss: 0.0624\tAccuracy: 49007.0/50000 (98%)\n",
      "\n",
      "Test set:\n",
      "default: Loss: 0.3951\tAccuracy: 8913.0/10000 (89%)\n",
      "\n",
      "Train Epoch: 52 [0/50000 (0%)]\tLosses default: 0.178115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 52 [10000/50000 (20%)]\tLosses default: 0.085960\n",
      "Train Epoch: 52 [20000/50000 (40%)]\tLosses default: 0.086123\n",
      "Train Epoch: 52 [30000/50000 (60%)]\tLosses default: 0.057102\n",
      "Train Epoch: 52 [40000/50000 (80%)]\tLosses default: 0.165731\n",
      "Train Epoch: 52 [50000/50000 (100%)]\tLosses default: 0.039097\n",
      "Test set:\n",
      "default: Loss: 0.0594\tAccuracy: 49050.0/50000 (98%)\n",
      "\n",
      "Test set:\n",
      "default: Loss: 0.4022\tAccuracy: 8898.0/10000 (89%)\n",
      "\n",
      "Train Epoch: 53 [0/50000 (0%)]\tLosses default: 0.102259\n",
      "Train Epoch: 53 [10000/50000 (20%)]\tLosses default: 0.144708\n",
      "Train Epoch: 53 [20000/50000 (40%)]\tLosses default: 0.139803\n",
      "Train Epoch: 53 [30000/50000 (60%)]\tLosses default: 0.070363\n",
      "Train Epoch: 53 [40000/50000 (80%)]\tLosses default: 0.072564\n",
      "Train Epoch: 53 [50000/50000 (100%)]\tLosses default: 0.019068\n",
      "Test set:\n",
      "default: Loss: 0.0618\tAccuracy: 49009.0/50000 (98%)\n",
      "\n",
      "Test set:\n",
      "default: Loss: 0.4093\tAccuracy: 8878.0/10000 (89%)\n",
      "\n",
      "Train Epoch: 54 [0/50000 (0%)]\tLosses default: 0.027055\n",
      "Train Epoch: 54 [10000/50000 (20%)]\tLosses default: 0.130081\n",
      "Train Epoch: 54 [20000/50000 (40%)]\tLosses default: 0.140828\n",
      "Train Epoch: 54 [30000/50000 (60%)]\tLosses default: 0.013491\n",
      "Train Epoch: 54 [40000/50000 (80%)]\tLosses default: 0.010251\n",
      "Train Epoch: 54 [50000/50000 (100%)]\tLosses default: 0.074942\n",
      "Test set:\n",
      "default: Loss: 0.0582\tAccuracy: 49039.0/50000 (98%)\n",
      "\n",
      "Test set:\n",
      "default: Loss: 0.4162\tAccuracy: 8857.0/10000 (89%)\n",
      "\n",
      "Train Epoch: 55 [0/50000 (0%)]\tLosses default: 0.096091\n",
      "Train Epoch: 55 [10000/50000 (20%)]\tLosses default: 0.043162\n",
      "Train Epoch: 55 [20000/50000 (40%)]\tLosses default: 0.050336\n",
      "Train Epoch: 55 [30000/50000 (60%)]\tLosses default: 0.056119\n",
      "Train Epoch: 55 [40000/50000 (80%)]\tLosses default: 0.053293\n",
      "Train Epoch: 55 [50000/50000 (100%)]\tLosses default: 0.058873\n",
      "Test set:\n",
      "default: Loss: 0.0537\tAccuracy: 49182.0/50000 (98%)\n",
      "\n",
      "Test set:\n",
      "default: Loss: 0.4139\tAccuracy: 8887.0/10000 (89%)\n",
      "\n",
      "Train Epoch: 56 [0/50000 (0%)]\tLosses default: 0.092896\n",
      "Train Epoch: 56 [10000/50000 (20%)]\tLosses default: 0.018789\n",
      "Train Epoch: 56 [20000/50000 (40%)]\tLosses default: 0.087305\n",
      "Train Epoch: 56 [30000/50000 (60%)]\tLosses default: 0.015577\n",
      "Train Epoch: 56 [40000/50000 (80%)]\tLosses default: 0.053281\n",
      "Train Epoch: 56 [50000/50000 (100%)]\tLosses default: 0.054921\n",
      "Test set:\n",
      "default: Loss: 0.0753\tAccuracy: 48679.0/50000 (97%)\n",
      "\n",
      "Test set:\n",
      "default: Loss: 0.4387\tAccuracy: 8785.0/10000 (88%)\n",
      "\n",
      "Train Epoch: 57 [0/50000 (0%)]\tLosses default: 0.066267\n",
      "Train Epoch: 57 [10000/50000 (20%)]\tLosses default: 0.108917\n",
      "Train Epoch: 57 [20000/50000 (40%)]\tLosses default: 0.114120\n",
      "Train Epoch: 57 [30000/50000 (60%)]\tLosses default: 0.038252\n",
      "Train Epoch: 57 [40000/50000 (80%)]\tLosses default: 0.041845\n",
      "Train Epoch: 57 [50000/50000 (100%)]\tLosses default: 0.030001\n",
      "Test set:\n",
      "default: Loss: 0.0550\tAccuracy: 49094.0/50000 (98%)\n",
      "\n",
      "Test set:\n",
      "default: Loss: 0.4264\tAccuracy: 8857.0/10000 (89%)\n",
      "\n",
      "Train Epoch: 58 [0/50000 (0%)]\tLosses default: 0.015851\n",
      "Train Epoch: 58 [10000/50000 (20%)]\tLosses default: 0.009423\n",
      "Train Epoch: 58 [20000/50000 (40%)]\tLosses default: 0.040005\n",
      "Train Epoch: 58 [30000/50000 (60%)]\tLosses default: 0.076778\n",
      "Train Epoch: 58 [40000/50000 (80%)]\tLosses default: 0.066126\n",
      "Train Epoch: 58 [50000/50000 (100%)]\tLosses default: 0.109764\n",
      "Test set:\n",
      "default: Loss: 0.0492\tAccuracy: 49242.0/50000 (98%)\n",
      "\n",
      "Test set:\n",
      "default: Loss: 0.4197\tAccuracy: 8884.0/10000 (89%)\n",
      "\n",
      "Train Epoch: 59 [0/50000 (0%)]\tLosses default: 0.035788\n",
      "Train Epoch: 59 [10000/50000 (20%)]\tLosses default: 0.045087\n",
      "Train Epoch: 59 [20000/50000 (40%)]\tLosses default: 0.091347\n",
      "Train Epoch: 59 [30000/50000 (60%)]\tLosses default: 0.074284\n",
      "Train Epoch: 59 [40000/50000 (80%)]\tLosses default: 0.084036\n",
      "Train Epoch: 59 [50000/50000 (100%)]\tLosses default: 0.087562\n",
      "Test set:\n",
      "default: Loss: 0.0527\tAccuracy: 49151.0/50000 (98%)\n",
      "\n",
      "Test set:\n",
      "default: Loss: 0.4265\tAccuracy: 8854.0/10000 (89%)\n",
      "\n",
      "Train Epoch: 60 [0/50000 (0%)]\tLosses default: 0.027132\n",
      "Train Epoch: 60 [10000/50000 (20%)]\tLosses default: 0.081560\n",
      "Train Epoch: 60 [20000/50000 (40%)]\tLosses default: 0.115081\n",
      "Train Epoch: 60 [30000/50000 (60%)]\tLosses default: 0.097662\n",
      "Train Epoch: 60 [40000/50000 (80%)]\tLosses default: 0.026425\n",
      "Train Epoch: 60 [50000/50000 (100%)]\tLosses default: 0.019077\n",
      "Test set:\n",
      "default: Loss: 0.0459\tAccuracy: 49321.0/50000 (99%)\n",
      "\n",
      "Test set:\n",
      "default: Loss: 0.4282\tAccuracy: 8868.0/10000 (89%)\n",
      "\n",
      "Train Epoch: 61 [0/50000 (0%)]\tLosses default: 0.061946\n",
      "Train Epoch: 61 [10000/50000 (20%)]\tLosses default: 0.018824\n",
      "Train Epoch: 61 [20000/50000 (40%)]\tLosses default: 0.024630\n",
      "Train Epoch: 61 [30000/50000 (60%)]\tLosses default: 0.072166\n",
      "Train Epoch: 61 [40000/50000 (80%)]\tLosses default: 0.189541\n",
      "Train Epoch: 61 [50000/50000 (100%)]\tLosses default: 0.110647\n",
      "Test set:\n",
      "default: Loss: 0.0490\tAccuracy: 49223.0/50000 (98%)\n",
      "\n",
      "Test set:\n",
      "default: Loss: 0.4366\tAccuracy: 8875.0/10000 (89%)\n",
      "\n",
      "Train Epoch: 62 [0/50000 (0%)]\tLosses default: 0.064228\n",
      "Train Epoch: 62 [10000/50000 (20%)]\tLosses default: 0.059726\n",
      "Train Epoch: 62 [20000/50000 (40%)]\tLosses default: 0.026973\n",
      "Train Epoch: 62 [30000/50000 (60%)]\tLosses default: 0.039064\n",
      "Train Epoch: 62 [40000/50000 (80%)]\tLosses default: 0.039375\n",
      "Train Epoch: 62 [50000/50000 (100%)]\tLosses default: 0.065699\n",
      "Test set:\n",
      "default: Loss: 0.0489\tAccuracy: 49215.0/50000 (98%)\n",
      "\n",
      "Test set:\n",
      "default: Loss: 0.4473\tAccuracy: 8859.0/10000 (89%)\n",
      "\n",
      "Train Epoch: 63 [0/50000 (0%)]\tLosses default: 0.095666\n",
      "Train Epoch: 63 [10000/50000 (20%)]\tLosses default: 0.039631\n",
      "Train Epoch: 63 [20000/50000 (40%)]\tLosses default: 0.058281\n",
      "Train Epoch: 63 [30000/50000 (60%)]\tLosses default: 0.025804\n",
      "Train Epoch: 63 [40000/50000 (80%)]\tLosses default: 0.064507\n",
      "Train Epoch: 63 [50000/50000 (100%)]\tLosses default: 0.144823\n",
      "Test set:\n",
      "default: Loss: 0.0541\tAccuracy: 49069.0/50000 (98%)\n",
      "\n",
      "Test set:\n",
      "default: Loss: 0.4491\tAccuracy: 8851.0/10000 (89%)\n",
      "\n",
      "Train Epoch: 64 [0/50000 (0%)]\tLosses default: 0.136020\n",
      "Train Epoch: 64 [10000/50000 (20%)]\tLosses default: 0.064920\n",
      "Train Epoch: 64 [20000/50000 (40%)]\tLosses default: 0.047294\n",
      "Train Epoch: 64 [30000/50000 (60%)]\tLosses default: 0.027718\n",
      "Train Epoch: 64 [40000/50000 (80%)]\tLosses default: 0.037201\n",
      "Train Epoch: 64 [50000/50000 (100%)]\tLosses default: 0.069173\n",
      "Test set:\n",
      "default: Loss: 0.0459\tAccuracy: 49222.0/50000 (98%)\n",
      "\n",
      "Test set:\n",
      "default: Loss: 0.4474\tAccuracy: 8896.0/10000 (89%)\n",
      "\n",
      "Train Epoch: 65 [0/50000 (0%)]\tLosses default: 0.074809\n",
      "Train Epoch: 65 [10000/50000 (20%)]\tLosses default: 0.038239\n",
      "Train Epoch: 65 [20000/50000 (40%)]\tLosses default: 0.077028\n",
      "Train Epoch: 65 [30000/50000 (60%)]\tLosses default: 0.026449\n",
      "Train Epoch: 65 [40000/50000 (80%)]\tLosses default: 0.110936\n",
      "Train Epoch: 65 [50000/50000 (100%)]\tLosses default: 0.103154\n",
      "Test set:\n",
      "default: Loss: 0.0489\tAccuracy: 49150.0/50000 (98%)\n",
      "\n",
      "Test set:\n",
      "default: Loss: 0.4592\tAccuracy: 8851.0/10000 (89%)\n",
      "\n",
      "Train Epoch: 66 [0/50000 (0%)]\tLosses default: 0.008963\n",
      "Train Epoch: 66 [10000/50000 (20%)]\tLosses default: 0.043704\n",
      "Train Epoch: 66 [20000/50000 (40%)]\tLosses default: 0.170778\n",
      "Train Epoch: 66 [30000/50000 (60%)]\tLosses default: 0.079891\n",
      "Train Epoch: 66 [40000/50000 (80%)]\tLosses default: 0.037826\n",
      "Train Epoch: 66 [50000/50000 (100%)]\tLosses default: 0.131765\n",
      "Test set:\n",
      "default: Loss: 0.0631\tAccuracy: 48878.0/50000 (98%)\n",
      "\n",
      "Test set:\n",
      "default: Loss: 0.4738\tAccuracy: 8836.0/10000 (88%)\n",
      "\n",
      "Train Epoch: 67 [0/50000 (0%)]\tLosses default: 0.033927\n",
      "Train Epoch: 67 [10000/50000 (20%)]\tLosses default: 0.072906\n",
      "Train Epoch: 67 [20000/50000 (40%)]\tLosses default: 0.097141\n",
      "Train Epoch: 67 [30000/50000 (60%)]\tLosses default: 0.083292\n",
      "Train Epoch: 67 [40000/50000 (80%)]\tLosses default: 0.033128\n",
      "Train Epoch: 67 [50000/50000 (100%)]\tLosses default: 0.059245\n",
      "Test set:\n",
      "default: Loss: 0.0459\tAccuracy: 49226.0/50000 (98%)\n",
      "\n",
      "Test set:\n",
      "default: Loss: 0.4589\tAccuracy: 8850.0/10000 (88%)\n",
      "\n",
      "Train Epoch: 68 [0/50000 (0%)]\tLosses default: 0.014646\n",
      "Train Epoch: 68 [10000/50000 (20%)]\tLosses default: 0.029336\n",
      "Train Epoch: 68 [20000/50000 (40%)]\tLosses default: 0.052231\n",
      "Train Epoch: 68 [30000/50000 (60%)]\tLosses default: 0.026985\n",
      "Train Epoch: 68 [40000/50000 (80%)]\tLosses default: 0.048299\n",
      "Train Epoch: 68 [50000/50000 (100%)]\tLosses default: 0.078970\n",
      "Test set:\n",
      "default: Loss: 0.0649\tAccuracy: 48802.0/50000 (98%)\n",
      "\n",
      "Test set:\n",
      "default: Loss: 0.4862\tAccuracy: 8805.0/10000 (88%)\n",
      "\n",
      "Train Epoch: 69 [0/50000 (0%)]\tLosses default: 0.016123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 69 [10000/50000 (20%)]\tLosses default: 0.060451\n",
      "Train Epoch: 69 [20000/50000 (40%)]\tLosses default: 0.122995\n",
      "Train Epoch: 69 [30000/50000 (60%)]\tLosses default: 0.041991\n",
      "Train Epoch: 69 [40000/50000 (80%)]\tLosses default: 0.095640\n",
      "Train Epoch: 69 [50000/50000 (100%)]\tLosses default: 0.027004\n",
      "Test set:\n",
      "default: Loss: 0.0439\tAccuracy: 49265.0/50000 (99%)\n",
      "\n",
      "Test set:\n",
      "default: Loss: 0.4628\tAccuracy: 8881.0/10000 (89%)\n",
      "\n",
      "Train Epoch: 70 [0/50000 (0%)]\tLosses default: 0.151189\n",
      "Train Epoch: 70 [10000/50000 (20%)]\tLosses default: 0.077595\n",
      "Train Epoch: 70 [20000/50000 (40%)]\tLosses default: 0.042039\n",
      "Train Epoch: 70 [30000/50000 (60%)]\tLosses default: 0.013015\n",
      "Train Epoch: 70 [40000/50000 (80%)]\tLosses default: 0.112711\n",
      "Train Epoch: 70 [50000/50000 (100%)]\tLosses default: 0.113347\n",
      "Test set:\n",
      "default: Loss: 0.0363\tAccuracy: 49428.0/50000 (99%)\n",
      "\n",
      "Test set:\n",
      "default: Loss: 0.4714\tAccuracy: 8878.0/10000 (89%)\n",
      "\n",
      "Train Epoch: 71 [0/50000 (0%)]\tLosses default: 0.060565\n",
      "Train Epoch: 71 [10000/50000 (20%)]\tLosses default: 0.080759\n",
      "Train Epoch: 71 [20000/50000 (40%)]\tLosses default: 0.071594\n",
      "Train Epoch: 71 [30000/50000 (60%)]\tLosses default: 0.371398\n",
      "Train Epoch: 71 [40000/50000 (80%)]\tLosses default: 0.128892\n",
      "Train Epoch: 71 [50000/50000 (100%)]\tLosses default: 0.077497\n",
      "Test set:\n",
      "default: Loss: 0.0352\tAccuracy: 49477.0/50000 (99%)\n",
      "\n",
      "Test set:\n",
      "default: Loss: 0.4705\tAccuracy: 8865.0/10000 (89%)\n",
      "\n",
      "Train Epoch: 72 [0/50000 (0%)]\tLosses default: 0.021562\n",
      "Train Epoch: 72 [10000/50000 (20%)]\tLosses default: 0.009366\n",
      "Train Epoch: 72 [20000/50000 (40%)]\tLosses default: 0.110685\n",
      "Train Epoch: 72 [30000/50000 (60%)]\tLosses default: 0.082103\n",
      "Train Epoch: 72 [40000/50000 (80%)]\tLosses default: 0.141061\n",
      "Train Epoch: 72 [50000/50000 (100%)]\tLosses default: 0.041916\n",
      "Test set:\n",
      "default: Loss: 0.0443\tAccuracy: 49262.0/50000 (99%)\n",
      "\n",
      "Test set:\n",
      "default: Loss: 0.4876\tAccuracy: 8832.0/10000 (88%)\n",
      "\n",
      "Train Epoch: 73 [0/50000 (0%)]\tLosses default: 0.063801\n",
      "Train Epoch: 73 [10000/50000 (20%)]\tLosses default: 0.025883\n",
      "Train Epoch: 73 [20000/50000 (40%)]\tLosses default: 0.022187\n",
      "Train Epoch: 73 [30000/50000 (60%)]\tLosses default: 0.132160\n",
      "Train Epoch: 73 [40000/50000 (80%)]\tLosses default: 0.022862\n",
      "Train Epoch: 73 [50000/50000 (100%)]\tLosses default: 0.035583\n",
      "Test set:\n",
      "default: Loss: 0.0394\tAccuracy: 49378.0/50000 (99%)\n",
      "\n",
      "Test set:\n",
      "default: Loss: 0.4834\tAccuracy: 8831.0/10000 (88%)\n",
      "\n",
      "Train Epoch: 74 [0/50000 (0%)]\tLosses default: 0.046622\n",
      "Train Epoch: 74 [10000/50000 (20%)]\tLosses default: 0.159144\n",
      "Train Epoch: 74 [20000/50000 (40%)]\tLosses default: 0.057520\n",
      "Train Epoch: 74 [30000/50000 (60%)]\tLosses default: 0.075245\n",
      "Train Epoch: 74 [40000/50000 (80%)]\tLosses default: 0.057716\n",
      "Train Epoch: 74 [50000/50000 (100%)]\tLosses default: 0.073725\n",
      "Test set:\n",
      "default: Loss: 0.0361\tAccuracy: 49413.0/50000 (99%)\n",
      "\n",
      "Test set:\n",
      "default: Loss: 0.4854\tAccuracy: 8845.0/10000 (88%)\n",
      "\n",
      "Train Epoch: 75 [0/50000 (0%)]\tLosses default: 0.023134\n",
      "Train Epoch: 75 [10000/50000 (20%)]\tLosses default: 0.033417\n",
      "Train Epoch: 75 [20000/50000 (40%)]\tLosses default: 0.060147\n",
      "Train Epoch: 75 [30000/50000 (60%)]\tLosses default: 0.063360\n",
      "Train Epoch: 75 [40000/50000 (80%)]\tLosses default: 0.018345\n",
      "Train Epoch: 75 [50000/50000 (100%)]\tLosses default: 0.100104\n",
      "Test set:\n",
      "default: Loss: 0.0403\tAccuracy: 49276.0/50000 (99%)\n",
      "\n",
      "Test set:\n",
      "default: Loss: 0.4977\tAccuracy: 8852.0/10000 (89%)\n",
      "\n",
      "Train Epoch: 76 [0/50000 (0%)]\tLosses default: 0.035970\n",
      "Train Epoch: 76 [10000/50000 (20%)]\tLosses default: 0.047880\n",
      "Train Epoch: 76 [20000/50000 (40%)]\tLosses default: 0.094313\n",
      "Train Epoch: 76 [30000/50000 (60%)]\tLosses default: 0.026160\n",
      "Train Epoch: 76 [40000/50000 (80%)]\tLosses default: 0.073556\n",
      "Train Epoch: 76 [50000/50000 (100%)]\tLosses default: 0.109474\n",
      "Test set:\n",
      "default: Loss: 0.0334\tAccuracy: 49455.0/50000 (99%)\n",
      "\n",
      "Test set:\n",
      "default: Loss: 0.4949\tAccuracy: 8850.0/10000 (88%)\n",
      "\n",
      "Train Epoch: 77 [0/50000 (0%)]\tLosses default: 0.014410\n",
      "Train Epoch: 77 [10000/50000 (20%)]\tLosses default: 0.045352\n",
      "Train Epoch: 77 [20000/50000 (40%)]\tLosses default: 0.078579\n",
      "Train Epoch: 77 [30000/50000 (60%)]\tLosses default: 0.077347\n",
      "Train Epoch: 77 [40000/50000 (80%)]\tLosses default: 0.044150\n",
      "Train Epoch: 77 [50000/50000 (100%)]\tLosses default: 0.075369\n",
      "Test set:\n",
      "default: Loss: 0.0329\tAccuracy: 49454.0/50000 (99%)\n",
      "\n",
      "Test set:\n",
      "default: Loss: 0.4951\tAccuracy: 8868.0/10000 (89%)\n",
      "\n",
      "Train Epoch: 78 [0/50000 (0%)]\tLosses default: 0.075264\n",
      "Train Epoch: 78 [10000/50000 (20%)]\tLosses default: 0.070111\n",
      "Train Epoch: 78 [20000/50000 (40%)]\tLosses default: 0.052212\n",
      "Train Epoch: 78 [30000/50000 (60%)]\tLosses default: 0.030586\n",
      "Train Epoch: 78 [40000/50000 (80%)]\tLosses default: 0.087533\n",
      "Train Epoch: 78 [50000/50000 (100%)]\tLosses default: 0.010499\n",
      "Test set:\n",
      "default: Loss: 0.0357\tAccuracy: 49405.0/50000 (99%)\n",
      "\n",
      "Test set:\n",
      "default: Loss: 0.4979\tAccuracy: 8857.0/10000 (89%)\n",
      "\n",
      "Train Epoch: 79 [0/50000 (0%)]\tLosses default: 0.057954\n",
      "Train Epoch: 79 [10000/50000 (20%)]\tLosses default: 0.014759\n",
      "Train Epoch: 79 [20000/50000 (40%)]\tLosses default: 0.022704\n",
      "Train Epoch: 79 [30000/50000 (60%)]\tLosses default: 0.087567\n",
      "Train Epoch: 79 [40000/50000 (80%)]\tLosses default: 0.009254\n",
      "Train Epoch: 79 [50000/50000 (100%)]\tLosses default: 0.009567\n",
      "Test set:\n",
      "default: Loss: 0.0284\tAccuracy: 49547.0/50000 (99%)\n",
      "\n",
      "Test set:\n",
      "default: Loss: 0.4977\tAccuracy: 8886.0/10000 (89%)\n",
      "\n",
      "Train Epoch: 80 [0/50000 (0%)]\tLosses default: 0.082956\n",
      "Train Epoch: 80 [10000/50000 (20%)]\tLosses default: 0.083384\n",
      "Train Epoch: 80 [20000/50000 (40%)]\tLosses default: 0.006972\n",
      "Train Epoch: 80 [30000/50000 (60%)]\tLosses default: 0.020468\n",
      "Train Epoch: 80 [40000/50000 (80%)]\tLosses default: 0.041328\n",
      "Train Epoch: 80 [50000/50000 (100%)]\tLosses default: 0.049267\n",
      "Test set:\n",
      "default: Loss: 0.0289\tAccuracy: 49586.0/50000 (99%)\n",
      "\n",
      "Test set:\n",
      "default: Loss: 0.5033\tAccuracy: 8849.0/10000 (88%)\n",
      "\n",
      "Train Epoch: 81 [0/50000 (0%)]\tLosses default: 0.005118\n",
      "Train Epoch: 81 [10000/50000 (20%)]\tLosses default: 0.021123\n",
      "Train Epoch: 81 [20000/50000 (40%)]\tLosses default: 0.031460\n",
      "Train Epoch: 81 [30000/50000 (60%)]\tLosses default: 0.063689\n",
      "Train Epoch: 81 [40000/50000 (80%)]\tLosses default: 0.030793\n",
      "Train Epoch: 81 [50000/50000 (100%)]\tLosses default: 0.065647\n",
      "Test set:\n",
      "default: Loss: 0.0286\tAccuracy: 49569.0/50000 (99%)\n",
      "\n",
      "Test set:\n",
      "default: Loss: 0.5073\tAccuracy: 8829.0/10000 (88%)\n",
      "\n",
      "Train Epoch: 82 [0/50000 (0%)]\tLosses default: 0.021715\n",
      "Train Epoch: 82 [10000/50000 (20%)]\tLosses default: 0.042179\n",
      "Train Epoch: 82 [20000/50000 (40%)]\tLosses default: 0.009819\n",
      "Train Epoch: 82 [30000/50000 (60%)]\tLosses default: 0.016585\n",
      "Train Epoch: 82 [40000/50000 (80%)]\tLosses default: 0.019954\n",
      "Train Epoch: 82 [50000/50000 (100%)]\tLosses default: 0.005635\n",
      "Test set:\n",
      "default: Loss: 0.0306\tAccuracy: 49494.0/50000 (99%)\n",
      "\n",
      "Test set:\n",
      "default: Loss: 0.5141\tAccuracy: 8833.0/10000 (88%)\n",
      "\n",
      "Train Epoch: 83 [0/50000 (0%)]\tLosses default: 0.013703\n",
      "Train Epoch: 83 [10000/50000 (20%)]\tLosses default: 0.041471\n",
      "Train Epoch: 83 [20000/50000 (40%)]\tLosses default: 0.036316\n",
      "Train Epoch: 83 [30000/50000 (60%)]\tLosses default: 0.029397\n",
      "Train Epoch: 83 [40000/50000 (80%)]\tLosses default: 0.037934\n",
      "Train Epoch: 83 [50000/50000 (100%)]\tLosses default: 0.043765\n",
      "Test set:\n",
      "default: Loss: 0.0316\tAccuracy: 49466.0/50000 (99%)\n",
      "\n",
      "Test set:\n",
      "default: Loss: 0.5245\tAccuracy: 8830.0/10000 (88%)\n",
      "\n",
      "Train Epoch: 84 [0/50000 (0%)]\tLosses default: 0.007648\n",
      "Train Epoch: 84 [10000/50000 (20%)]\tLosses default: 0.021627\n",
      "Train Epoch: 84 [20000/50000 (40%)]\tLosses default: 0.017981\n",
      "Train Epoch: 84 [30000/50000 (60%)]\tLosses default: 0.025490\n",
      "Train Epoch: 84 [40000/50000 (80%)]\tLosses default: 0.091320\n",
      "Train Epoch: 84 [50000/50000 (100%)]\tLosses default: 0.034062\n",
      "Test set:\n",
      "default: Loss: 0.0301\tAccuracy: 49523.0/50000 (99%)\n",
      "\n",
      "Test set:\n",
      "default: Loss: 0.5198\tAccuracy: 8839.0/10000 (88%)\n",
      "\n",
      "Train Epoch: 85 [0/50000 (0%)]\tLosses default: 0.066646\n",
      "Train Epoch: 85 [10000/50000 (20%)]\tLosses default: 0.017341\n",
      "Train Epoch: 85 [20000/50000 (40%)]\tLosses default: 0.035519\n",
      "Train Epoch: 85 [30000/50000 (60%)]\tLosses default: 0.033889\n",
      "Train Epoch: 85 [40000/50000 (80%)]\tLosses default: 0.047553\n",
      "Train Epoch: 85 [50000/50000 (100%)]\tLosses default: 0.068233\n",
      "Test set:\n",
      "default: Loss: 0.0366\tAccuracy: 49366.0/50000 (99%)\n",
      "\n",
      "Test set:\n",
      "default: Loss: 0.5395\tAccuracy: 8833.0/10000 (88%)\n",
      "\n",
      "Train Epoch: 86 [0/50000 (0%)]\tLosses default: 0.064380\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 86 [10000/50000 (20%)]\tLosses default: 0.054146\n",
      "Train Epoch: 86 [20000/50000 (40%)]\tLosses default: 0.018501\n",
      "Train Epoch: 86 [30000/50000 (60%)]\tLosses default: 0.032854\n",
      "Train Epoch: 86 [40000/50000 (80%)]\tLosses default: 0.194431\n",
      "Train Epoch: 86 [50000/50000 (100%)]\tLosses default: 0.048328\n",
      "Test set:\n",
      "default: Loss: 0.0264\tAccuracy: 49614.0/50000 (99%)\n",
      "\n",
      "Test set:\n",
      "default: Loss: 0.5317\tAccuracy: 8868.0/10000 (89%)\n",
      "\n",
      "Train Epoch: 87 [0/50000 (0%)]\tLosses default: 0.033393\n",
      "Train Epoch: 87 [10000/50000 (20%)]\tLosses default: 0.007968\n",
      "Train Epoch: 87 [20000/50000 (40%)]\tLosses default: 0.010875\n",
      "Train Epoch: 87 [30000/50000 (60%)]\tLosses default: 0.052005\n",
      "Train Epoch: 87 [40000/50000 (80%)]\tLosses default: 0.004819\n",
      "Train Epoch: 87 [50000/50000 (100%)]\tLosses default: 0.063388\n",
      "Test set:\n",
      "default: Loss: 0.0237\tAccuracy: 49655.0/50000 (99%)\n",
      "\n",
      "Test set:\n",
      "default: Loss: 0.5305\tAccuracy: 8867.0/10000 (89%)\n",
      "\n",
      "Train Epoch: 88 [0/50000 (0%)]\tLosses default: 0.018399\n",
      "Train Epoch: 88 [10000/50000 (20%)]\tLosses default: 0.001137\n",
      "Train Epoch: 88 [20000/50000 (40%)]\tLosses default: 0.019843\n",
      "Train Epoch: 88 [30000/50000 (60%)]\tLosses default: 0.010773\n",
      "Train Epoch: 88 [40000/50000 (80%)]\tLosses default: 0.008583\n",
      "Train Epoch: 88 [50000/50000 (100%)]\tLosses default: 0.017484\n",
      "Test set:\n",
      "default: Loss: 0.0228\tAccuracy: 49695.0/50000 (99%)\n",
      "\n",
      "Test set:\n",
      "default: Loss: 0.5276\tAccuracy: 8842.0/10000 (88%)\n",
      "\n",
      "Train Epoch: 89 [0/50000 (0%)]\tLosses default: 0.052487\n",
      "Train Epoch: 89 [10000/50000 (20%)]\tLosses default: 0.012062\n",
      "Train Epoch: 89 [20000/50000 (40%)]\tLosses default: 0.056971\n",
      "Train Epoch: 89 [30000/50000 (60%)]\tLosses default: 0.014858\n",
      "Train Epoch: 89 [40000/50000 (80%)]\tLosses default: 0.028436\n",
      "Train Epoch: 89 [50000/50000 (100%)]\tLosses default: 0.064116\n",
      "Test set:\n",
      "default: Loss: 0.0253\tAccuracy: 49636.0/50000 (99%)\n",
      "\n",
      "Test set:\n",
      "default: Loss: 0.5363\tAccuracy: 8847.0/10000 (88%)\n",
      "\n",
      "Train Epoch: 90 [0/50000 (0%)]\tLosses default: 0.034230\n",
      "Train Epoch: 90 [10000/50000 (20%)]\tLosses default: 0.012853\n",
      "Train Epoch: 90 [20000/50000 (40%)]\tLosses default: 0.014554\n",
      "Train Epoch: 90 [30000/50000 (60%)]\tLosses default: 0.067595\n",
      "Train Epoch: 90 [40000/50000 (80%)]\tLosses default: 0.125444\n",
      "Train Epoch: 90 [50000/50000 (100%)]\tLosses default: 0.010439\n",
      "Test set:\n",
      "default: Loss: 0.0211\tAccuracy: 49699.0/50000 (99%)\n",
      "\n",
      "Test set:\n",
      "default: Loss: 0.5315\tAccuracy: 8831.0/10000 (88%)\n",
      "\n",
      "Train Epoch: 91 [0/50000 (0%)]\tLosses default: 0.006228\n",
      "Train Epoch: 91 [10000/50000 (20%)]\tLosses default: 0.011064\n",
      "Train Epoch: 91 [20000/50000 (40%)]\tLosses default: 0.005598\n",
      "Train Epoch: 91 [30000/50000 (60%)]\tLosses default: 0.012199\n",
      "Train Epoch: 91 [40000/50000 (80%)]\tLosses default: 0.015751\n",
      "Train Epoch: 91 [50000/50000 (100%)]\tLosses default: 0.014108\n",
      "Test set:\n",
      "default: Loss: 0.0301\tAccuracy: 49467.0/50000 (99%)\n",
      "\n",
      "Test set:\n",
      "default: Loss: 0.5482\tAccuracy: 8796.0/10000 (88%)\n",
      "\n",
      "Train Epoch: 92 [0/50000 (0%)]\tLosses default: 0.028300\n",
      "Train Epoch: 92 [10000/50000 (20%)]\tLosses default: 0.013542\n",
      "Train Epoch: 92 [20000/50000 (40%)]\tLosses default: 0.077315\n",
      "Train Epoch: 92 [30000/50000 (60%)]\tLosses default: 0.040226\n",
      "Train Epoch: 92 [40000/50000 (80%)]\tLosses default: 0.032825\n",
      "Train Epoch: 92 [50000/50000 (100%)]\tLosses default: 0.016713\n",
      "Test set:\n",
      "default: Loss: 0.0230\tAccuracy: 49648.0/50000 (99%)\n",
      "\n",
      "Test set:\n",
      "default: Loss: 0.5422\tAccuracy: 8851.0/10000 (89%)\n",
      "\n",
      "Train Epoch: 93 [0/50000 (0%)]\tLosses default: 0.026851\n",
      "Train Epoch: 93 [10000/50000 (20%)]\tLosses default: 0.054502\n",
      "Train Epoch: 93 [20000/50000 (40%)]\tLosses default: 0.032632\n",
      "Train Epoch: 93 [30000/50000 (60%)]\tLosses default: 0.080769\n",
      "Train Epoch: 93 [40000/50000 (80%)]\tLosses default: 0.068699\n",
      "Train Epoch: 93 [50000/50000 (100%)]\tLosses default: 0.052152\n",
      "Test set:\n",
      "default: Loss: 0.0220\tAccuracy: 49670.0/50000 (99%)\n",
      "\n",
      "Test set:\n",
      "default: Loss: 0.5392\tAccuracy: 8858.0/10000 (89%)\n",
      "\n",
      "Train Epoch: 94 [0/50000 (0%)]\tLosses default: 0.028292\n",
      "Train Epoch: 94 [10000/50000 (20%)]\tLosses default: 0.025239\n",
      "Train Epoch: 94 [20000/50000 (40%)]\tLosses default: 0.035807\n",
      "Train Epoch: 94 [30000/50000 (60%)]\tLosses default: 0.077014\n",
      "Train Epoch: 94 [40000/50000 (80%)]\tLosses default: 0.013692\n",
      "Train Epoch: 94 [50000/50000 (100%)]\tLosses default: 0.028558\n",
      "Test set:\n",
      "default: Loss: 0.0180\tAccuracy: 49763.0/50000 (100%)\n",
      "\n",
      "Test set:\n",
      "default: Loss: 0.5402\tAccuracy: 8847.0/10000 (88%)\n",
      "\n",
      "Train Epoch: 95 [0/50000 (0%)]\tLosses default: 0.021739\n",
      "Train Epoch: 95 [10000/50000 (20%)]\tLosses default: 0.058954\n",
      "Train Epoch: 95 [20000/50000 (40%)]\tLosses default: 0.062581\n",
      "Train Epoch: 95 [30000/50000 (60%)]\tLosses default: 0.035695\n",
      "Train Epoch: 95 [40000/50000 (80%)]\tLosses default: 0.030404\n",
      "Train Epoch: 95 [50000/50000 (100%)]\tLosses default: 0.013742\n",
      "Test set:\n",
      "default: Loss: 0.0213\tAccuracy: 49683.0/50000 (99%)\n",
      "\n",
      "Test set:\n",
      "default: Loss: 0.5533\tAccuracy: 8850.0/10000 (88%)\n",
      "\n",
      "Train Epoch: 96 [0/50000 (0%)]\tLosses default: 0.048467\n",
      "Train Epoch: 96 [10000/50000 (20%)]\tLosses default: 0.004754\n",
      "Train Epoch: 96 [20000/50000 (40%)]\tLosses default: 0.017654\n",
      "Train Epoch: 96 [30000/50000 (60%)]\tLosses default: 0.028818\n",
      "Train Epoch: 96 [40000/50000 (80%)]\tLosses default: 0.083033\n",
      "Train Epoch: 96 [50000/50000 (100%)]\tLosses default: 0.018888\n",
      "Test set:\n",
      "default: Loss: 0.0209\tAccuracy: 49673.0/50000 (99%)\n",
      "\n",
      "Test set:\n",
      "default: Loss: 0.5565\tAccuracy: 8838.0/10000 (88%)\n",
      "\n",
      "Train Epoch: 97 [0/50000 (0%)]\tLosses default: 0.043696\n",
      "Train Epoch: 97 [10000/50000 (20%)]\tLosses default: 0.002982\n",
      "Train Epoch: 97 [20000/50000 (40%)]\tLosses default: 0.014254\n",
      "Train Epoch: 97 [30000/50000 (60%)]\tLosses default: 0.017009\n",
      "Train Epoch: 97 [40000/50000 (80%)]\tLosses default: 0.104646\n",
      "Train Epoch: 97 [50000/50000 (100%)]\tLosses default: 0.047271\n",
      "Test set:\n",
      "default: Loss: 0.0248\tAccuracy: 49598.0/50000 (99%)\n",
      "\n",
      "Test set:\n",
      "default: Loss: 0.5597\tAccuracy: 8869.0/10000 (89%)\n",
      "\n",
      "Train Epoch: 98 [0/50000 (0%)]\tLosses default: 0.013779\n",
      "Train Epoch: 98 [10000/50000 (20%)]\tLosses default: 0.007737\n",
      "Train Epoch: 98 [20000/50000 (40%)]\tLosses default: 0.020388\n",
      "Train Epoch: 98 [30000/50000 (60%)]\tLosses default: 0.032267\n",
      "Train Epoch: 98 [40000/50000 (80%)]\tLosses default: 0.032988\n",
      "Train Epoch: 98 [50000/50000 (100%)]\tLosses default: 0.111938\n",
      "Test set:\n",
      "default: Loss: 0.0498\tAccuracy: 49039.0/50000 (98%)\n",
      "\n",
      "Test set:\n",
      "default: Loss: 0.6009\tAccuracy: 8725.0/10000 (87%)\n",
      "\n",
      "Train Epoch: 99 [0/50000 (0%)]\tLosses default: 0.060035\n",
      "Train Epoch: 99 [10000/50000 (20%)]\tLosses default: 0.012661\n",
      "Train Epoch: 99 [20000/50000 (40%)]\tLosses default: 0.037995\n",
      "Train Epoch: 99 [30000/50000 (60%)]\tLosses default: 0.019227\n",
      "Train Epoch: 99 [40000/50000 (80%)]\tLosses default: 0.035663\n",
      "Train Epoch: 99 [50000/50000 (100%)]\tLosses default: 0.006486\n",
      "Test set:\n",
      "default: Loss: 0.0166\tAccuracy: 49749.0/50000 (99%)\n",
      "\n",
      "Test set:\n",
      "default: Loss: 0.5601\tAccuracy: 8870.0/10000 (89%)\n",
      "\n",
      "Train Epoch: 100 [0/50000 (0%)]\tLosses default: 0.107079\n",
      "Train Epoch: 100 [10000/50000 (20%)]\tLosses default: 0.034436\n",
      "Train Epoch: 100 [20000/50000 (40%)]\tLosses default: 0.044546\n",
      "Train Epoch: 100 [30000/50000 (60%)]\tLosses default: 0.025975\n",
      "Train Epoch: 100 [40000/50000 (80%)]\tLosses default: 0.004248\n",
      "Train Epoch: 100 [50000/50000 (100%)]\tLosses default: 0.008908\n",
      "Test set:\n",
      "default: Loss: 0.0306\tAccuracy: 49455.0/50000 (99%)\n",
      "\n",
      "Test set:\n",
      "default: Loss: 0.5927\tAccuracy: 8816.0/10000 (88%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 101):\n",
    "    for model in models.values():\n",
    "        model.train()\n",
    "    train(epoch, models)\n",
    "    for model in models.values():\n",
    "        model.eval()\n",
    "    test(models, train_loader, train_log)\n",
    "    test(models, test_loader, test_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deXhU5fXA8e/JvgeyESAJBAg7soUAIgjiwlIRNwTFpbWirdbaqhVbl6pdbK1W/alVVNwQFVERFGUTFZAtLEKAQMKahC0BEpbsmff3xztAgAABMpkkcz7Pk4fMvXfmnsvAnLnvcl4xxqCUUspzebk7AKWUUu6liUAppTycJgKllPJwmgiUUsrDaSJQSikPp4lAKaU8nCYCpZTycJoIlFLKw2kiUOociYhPdbad62so5S6aCJRyEpFmIvKZiOSKyFYRud+5/a8iMlVEJonIQeCO02zzF5EXRWSn8+dFEfF3vsZAEckWkUdEZDfwjohEichXIpIvIvtFZIGI6P9JVev0H51SgPMDeAbwM9AcGAw8ICJXOQ+5BpgKNAI+PM22vwB9gG5AVyAFeKzSaWKBCKAFMA54EMgGooEmwJ8Brfmiap0mAqWsXkC0MeZpY0ypMWYL8CYw2rl/sTFmmjHGYYwpOs22W4CnjTF7jTG5wFPArZXO4QCeNMaUOI8vA5oCLYwxZcaYBUaLfyk30ESglNUCaOZspskXkXzsN/Qmzv1ZVTzn5G3NgO2VHm93bjsq1xhTXOnxc0AmMFtEtojI+Au6AqXOkyYCpawsYKsxplGln1BjzDDn/qq+qZ+8bSc2oRyV4NxW5fHGmEPGmAeNMa2AEcAfRWTwhV2GUudOE4FS1jLgkLMzN1BEvEWks4j0OofX+Ah4TESiRSQKeAKYdLqDReQXItJGRAQoACqwzUdK1SpNBEoBxpgK4BfYjt6tQB7wFhB+Di/zNyAVWAOsBVY6t51OEjAXOAwsBl4zxsw/5+CVukCifVNKKeXZ9I5AKaU8nCYCpZTycJoIlFLKw2kiUEopD1fvCl9FRUWZli1bujsMpZSqV1asWJFnjImual+9SwQtW7YkNTXV3WEopVS9IiLbT7dPm4aUUsrDaSJQSikPp4lAKaU8XL3rI6hKWVkZ2dnZFBcXn/3geiwgIIC4uDh8fX3dHYpSqgFpEIkgOzub0NBQWrZsia3f1fAYY9i3bx/Z2dkkJia6OxylVAPi0qYhERkiIhtFJPN0tdZFZJSIrBeRdSIy+XzOU1xcTGRkZINNAgAiQmRkZIO/61FK1T6X3RGIiDfwKnAFdjm+5SIy3RizvtIxScCjQD9jzAERibmA811oyHWeJ1yjUqr2ufKOIAXINMZsMcaUAh9j13it7C7gVWPMAQBjzF4XxqOUUnVbRRmseNf+WYtcmQiac+JSftnObZW1BdqKyCIRWSIiQ1wYj8vk5+fz2muvnfPzhg0bRn5+vgsiUkrVS5u+hRm/h/SvavW07h4+6oNdnGMgMAZ4U0QanXyQiIwTkVQRSc3Nza3lEM/udImgvLz8jM+bOXMmjRqdcrlKKU+Vtcz55/JaPa0rE0EOEF/pcZxzW2XZwHRjTJkxZiuwCZsYTmCMmWCMSTbGJEdHV1kqw63Gjx/P5s2b6datG7169aJ///6MGDGCjh07AjBy5Eh69uxJp06dmDBhwrHntWzZkry8PLZt20aHDh2466676NSpE1deeSVFRUXuuhyllLtkO8vnZC87cXt5KbwzDDZ+65LTunL46HIgSUQSsQlgNHDzScdMw94JvONc47UtsOVCTvrUjHWs33nwQl7iFB2bhfHk1Z1Ou//ZZ58lLS2N1atX8/333zN8+HDS0tKODfOcOHEiERERFBUV0atXL66//noiIyNPeI2MjAw++ugj3nzzTUaNGsVnn33G2LFja/Q6lFJ1WEUZ7FwF4g27fobyEvDxt/uylsD2RdD3Ppec2mV3BMaYcuA+YBawAZhijFknIk+LyAjnYbOAfSKyHpgPPGyM2eeqmGpLSkrKCWP9X375Zbp27UqfPn3IysoiIyPjlOckJibSrVs3AHr27Mm2bdtqK1ylVF2wJw3Ki6DTtVBRapPBUZlzwcsHEvu75NQunVBmjJkJzDxp2xOVfjfAH50/NeJM39xrS3Bw8LHfv//+e+bOncvixYsJCgpi4MCBVc4F8Pf3P/a7t7e3Ng0p5WmO9gv0/S2kTbX9BfEpdlvmd5DQF/xDXXJqd3cWNwihoaEcOnSoyn0FBQU0btyYoKAg0tPTWbJkSS1Hp5SqF7KXQ2hTaNYDGiUc7yc4tBv2rIXWl7ns1A2ixIS7RUZG0q9fPzp37kxgYCBNmjQ5tm/IkCG8/vrrdOjQgXbt2tGnTx83RqqUqrOyl0FcMohAXAps/8lu3/yd/bPN5S47tSaCGjJ5ctXVMfz9/fnmm2+q3He0HyAqKoq0tLRj2x966KEaj08pVYcdzoUD2yD5Tvs4PsU2DxVk2/6B4Bho0tllp9emIaWUcrdsZ/9AXK8T/9yxBDbPhzaDwct1H9eaCJRSyt2yl9tRQc3syEFiu4BPICybAEX7ofVgl55eE4FSSrlb9nL74e8baB97+0Kz7pC1FBBoPcilp9dEoJRS7lRRDjkrbAdxZfHO5qFm3SA4yqUhaGexUkq5S3kprP0UygqP9wscdTQxuHC00FGaCJRSqjY5HLBjsU0A66dB0QEIaw6tBp54XOIAaP8L6DrG5SFp01ANON8y1AAvvvgihYWFNRyRUqrOKdwPc56AF7vAu8NgzSf22/7NU+D+1RByUkHNgDAY/SFEtnZ5aJoIaoAmAqXUGTkc8Ont8NMr0KQTXPcWPJwJ178Fba8CHz+3hqdNQzWgchnqK664gpiYGKZMmUJJSQnXXnstTz31FEeOHGHUqFFkZ2dTUVHB448/zp49e9i5cyeDBg0iKiqK+fPnu/tSlFLVtWoSFO6D3r85+wf5sjdg649w9cvQ8/baie8cNLxE8M142L22Zl8ztgsMffa0uyuXoZ49ezZTp05l2bJlGGMYMWIEP/74I7m5uTRr1oyvv/4asDWIwsPDeeGFF5g/fz5RUa4dFaCUqkH7t8KMB8BRBms+hZGvQdOLqj42dyPM/Su0HQo9bqvVMKtLm4Zq2OzZs5k9ezbdu3enR48epKenk5GRQZcuXZgzZw6PPPIICxYsIDw83N2hKqXO13d/sxPArn4ZjuyFNwfBN4/YYaDGHD+uogw+Hwd+wTDiZVtHqA5qeHcEZ/jmXhuMMTz66KPcfffdp+xbuXIlM2fO5LHHHmPw4ME88cQTVbyCUsplCvfDvKdsTZ/TfYM/m52rbR2g/g/aZp4OV8Psx2D5W7D0dVs5tGlXOLgL8nfYRHHTJAiJqdlrqUF6R1ADKpehvuqqq5g4cSKHDx8GICcnh71797Jz506CgoIYO3YsDz/8MCtXrjzluUopF1vyP1jxLkwcAptmnf14RwX88Jx9TkWZ3Tb3SQiMgH6/t4+DImzT0MOZcM1rENUO9qaDfwgkXQkj/2eTRR3W8O4I3KByGeqhQ4dy880307dvXwBCQkKYNGkSmZmZPPzww3h5eeHr68v//vc/AMaNG8eQIUNo1qyZdhYr5Uolh23tnsQBUFwAH42Gq/4JKXeBl/epx1eUwRf32G//AItehk4jYcv3MORZCDipeTewMXS/xf7UM2Iqt2fVA8nJySY1NfWEbRs2bKBDhw5uiqh2edK1KlWjlrwO3z4Cd86xQzg/uws2fg1evtAoHhq3hJb9oeM1EB4PU38J6V/B4CchpqNtUtq73jb93Jd6fD3hekJEVhhjkqvap3cESqmGr6IMFr9il3s8uvzjTR9A2mf2w/3ANsjLtB/2856CoCgozIMh/4I+99jjk66A9K8hIrHeJYGz0USglGp4cjfZjtset9oqnuu+gIIsGPaf48d4ecNFo058Xn4WbJgBm76FLjfa51c+vuOI2om/ljWYRGCMQero0KyaUt+a8ZRyi0N7YNJ19oM/9W3bUZu7CaLb287bM2kUbxeP7/vb2om1jmgQo4YCAgLYt29fg/6gNMawb98+AgIC3B2KUnVX6RGYPMrO+L19Blw6HjZ/D3kb4eL7XbrKV33WIO4I4uLiyM7OJjc3192huFRAQABxcXHuDkOpuslRAVPvhN1rYPRkOzoocQD0vhu2LbSVPFWVGkQi8PX1JTEx0d1hKKXc5cg+mPYbyJhl+wHaDT2+Lyiiwbbt15QGkQiUUh5s+0/2TqAwzyaBlLvcHVG949IGMxEZIiIbRSRTRMZXsf8OEckVkdXOn1+7Mh6lVAOSlwlf/QHeHQ6+AXZ+gCaB8+KyOwIR8QZeBa4AsoHlIjLdGLP+pEM/Mcbc56o4lFINTM5K+OHfsOkb8PaDHrfDFU/bhVzUeXFl01AKkGmM2QIgIh8D1wAnJwKllDq7ogMw7xlInWjb/S99BHr9uk4Xc6svXJkImgNZlR5nA72rOO56ERkAbAL+YIzJOvkAERkHjANISEhwQahKqVpjjK3U6eVjO3VDY0/c76iA7OWwcSYUZNsSEF4+dpJX0X7o8xsY+KjeAdQgd3cWzwA+MsaUiMjdwHvAZScfZIyZAEwAW2uodkNUStWo1ZNh5kP2968egObJts5PRQmUl9imn8I8Zw2gBHCU2xIRMR3gqn+cf/lodVquTAQ5QHylx3HObccYY/ZVevgW8G8XxqOUcrfcjTYJtOxvK3hu+saWg965ytbv8faFVpdCu2G2ts/JFT6VS7gyESwHkkQkEZsARgM3Vz5ARJoaY3Y5H44ANrgwHqVUbTiSB0GRp67GVVYEn94BvkF20fbQWIjtDAMedkuY6jiXDR81xpQD9wGzsB/wU4wx60TkaRE5OrvjfhFZJyI/A/cDd7gqHqXUedi5Gmb9BRyO6h2/Ywn8JwlevwTWTLFNOo4K2LsBpt9vK31e+8ap/QLKrRrEegRKKReZcjusnwa3TbdNNmdijF35a/9me0eQmw4hTaC0EEqdq/D1fwgGP+76uNUpdD0CpdS5Kz1yfDnHVR+cPRFsmgVZS+AX/4Ued0DGbFg9CYJjIK4XxCVDVJLLw1bnThOBUqpqGbOhvAhiL4L102HYAbscY1UcFXZBl4hW0P1WW+Wz3RD7o+o8rcmqlLKjeTLmnrht3TQIjoarX7JDO9dOPf3z10617f+XPWZH/qh6Re8IlPJ0pUdg0vVwcCfc/aMdyVNaaO8Iuo6B5j3sXcHK947X8tmdBoteBL9gCG0GqybZYzpe695rUefFcxLBxm/sRJYb39PFKZSq7Pt/2tW8/MPg6z/CL7+1SaCsEDqNtMf0uM2O/9+52k7wmnQdGOy3/8I8e8yIl/T/Vj3lOYng4E7YMB0O5tjl6JRSsHstLH7NftDH94Yv74WfJ0PGHNss1KKfPa7LjTD7Mfuzc5Xdd9uX0LgFlJdC6WFb/0fVS56TCKLa2j/zNmkiUApsB++MB2wH8OVPQUAjWPkBzHnCTv7qOtou2A4Q2Ag6jIC1U+zav7dOg7Cmdp+PH/hoEqjPPOc+Lrqd/TNvk3vjUKquSJ0IOam2fk9QhG3WGf48FOXbZqGOI088/tJHIPlXcMfM40lANQiekwiCo23dEk0EStkmodmPQatBcNGo49tjO8MlD0BE6+PNQkdFtbFzBIIjazdW5XKekwhEIKod5GW4OxKl3Ku4AKbcZpuCrptwak2gyx6H360Ab89pOfZ0npMIwPYT5G50dxRK1a7C/VDiLPFgDEz7LRzYDje+W/WiLiKnJgfVoHlWyo9ua6e8F51hhqRSDcHKD+yQ6V0/w8Fsu61xIoQ2hR0/wZV/hxZ93RujqjM8KxEcGzmUAfEp7o1FKVdZ/radD9A4ERL62IVcykthz1rYsw66jYW+97o7SlWHeGgi2KSJQDVMmfNg5sOQdCWM+fj48E+lzsCz+ggatQBvP+0nUHXT4VxY8Lwdw38+9qbbhV+i28MNEzUJqGrzrETg7WOHxenIIVUXLXoR5j1tF4I5V/u3wuQbwScAbv4E/ENrPj7VYHlWIgDbYZyndwSqjqkotyt6+YVA6tuQ9nn1n7s7DSZeZUcG3TJFZ86rc+YxiWDVjgO8OHcTJjIJDmyD8hJ3h6TUcVvmw5G9cM0rdhGXGb+H/VvO/rztP8E7w8DLxxaLa9bd9bGqBseDEkE+L87N4EhYGzAO2LfZ3SEpddzPH9khze2G2/Z9Efj0l8fH/x9VWggLXoCPxsALneCdoXYuwK9mQUx798Su6j2PSQQJEUEA5PjE2Q1aakLVFcUFkP41dL7BFnBrlAAj/we718Abl8KuNfa4venw5mV2JbB9m+3Q0CuegTtna3OQuiAeM3w0IdImgs2OprQDTQSq7lj/JZQX20Vgjmo/3C4Y//ld8NZgWyZ69WS7EMytX0Dry9wXr2pwPOaOIK5xIABbDwLh8ZoIlHsZc/z3nz+GyCS7Elhlif3hnoXQaiAsfwua97SPNQmoGuYxdwRBfj5EhfiTtb/QTizTRKDcofggfPUAbJplP9jjesH2RbbQW1X1fYKjYMwnsGsVNO2mcwOUS3jMHQFAQkQgO44lggxwONwdkvIku9NgwkC7KHy7oVC4Dxb8x474qVwK+mReXjZpaBJQLuIxdwRgO4xTtx+AHu3twhv7Mo4vWKOUK6360Nb/CWgEd3wFLS6224/k2SKIjRLcG5/yaC69IxCRISKyUUQyRWT8GY67XkSMiCS7Mp6EiCB25hdR1mqw3bD+S1eeTik7X2XGA/Dlb20z0D0LjicBsE0/UUnui08pXJgIRMQbeBUYCnQExohIxyqOCwV+Dyx1VSxHxUcE4TCw0xEBCRef2+xNpZa+AdsXn7q9+GDV9YEKsmHiEFjxDlzyB7vOb1X1/5VyM1feEaQAmcaYLcaYUuBj4JoqjnsG+BdQ7MJYAJsIANtP0Pk6yN0Ae9a7+rSqIchZCd/8Cd6/BjLmHN++fTG83B1eSYGs5ce3b54Pr/e3fVE3TYLL/6orfqk6y5WJoDmQVelxtnPbMSLSA4g3xnx9phcSkXEikioiqbm5uecd0NFJZVn7i6DjNSBekPbZeb+e8iBLXwe/UNun9PHNkD7TLv7y3tV2LWwB3hkCi162FUQnXQchTWDcfOhwtbujV+qM3PYVRUS8gBeAO852rDFmAjABIDk52Zzl8NNqEhaAn7eXvSMISYDEAbDuc7jsMV2aT53ewV22GbHXr2HgI/DBdfDJLbZUSatBcOM7gMD038Gcx+1zOt8AV78E/iFuDV2p6nBlIsgBKs97j3NuOyoU6Ax8L/ZDOBaYLiIjjDGprgjI20uIaxxo5xIAdLoOZtwPu1ZrsS51esvfAkc59B5n6wHdNg2++A1EtobBTx5v8hn1vp39axzQfax+uVD1hisTwXIgSUQSsQlgNHDz0Z3GmAIg6uhjEfkeeMhVSeCo+Igge0cA9pb96z/a5iFNBKoqZUWQOhHaDYOIVnZbQDiMmXzqsSLQ/ZbajU+pGuCyPgJjTDlwHzAL2ABMMcasE5GnRWSEq857NgmVE0FQhJ2uv26aTi5TVVszBYr2Q9/fujsSpVzGpfMIjDEzjTFtjTGtjTF/d257whgzvYpjB7r6bgAgPiKQgqIyCgrL7IbON0BBFmye5+pTq/qmKB8WvwqxXaBFP3dHo5TLeFSJCag0cujA0X6Ca+1axvOe0rsCT1VWZIeEHth+fNuWH+B//WBfJgx8VNv7VYPmcQOb448NIS2kc/NwW//9ssdsud91n0OXG9wcobpgFeVQsMOWcwhoZGv1VOVInu0IXvYmFObZbZFJdoho+lcQ2QbunANxPWsvdqXcwGMTwbF+ArDNQ4tegu/+ZucXePu6KTp1wXYsga8fhD1p9rF4Q2Aj8PYDL1+bFMpL7F1AySEwFZB0FfS8wy5hmjnXVgNNGQeXPwV+Qe68GqVqhcclgrAAXxoH+Z6YCLy8YPATMHkUrHwfet3pvgDV+TmSB3OegNUfQlgcDH3OfsgfybVt/RWldgioowJ8/ME3CALCoMuNJxYe1E5h5YE8LhHASSOHjkq6EhL6wg//sh2DR9d/NQa2/ggbZkAf59hxVXcYA2s/hW8egZKD0O8BuPRPdiUvpVS1eGQiiI8IIi2n4MSNInDF0/DucHitN0S1sytDZc6F/c6F7ov224XF1bkrKwbfgJp9zQPbYeZDkDEbmifDNa9ATIeaPYdSHsDjRg2BTQTZB4qocJxUrSI+BR5YC8P+A8HRsPxNWy3y2jdseYH1X8Kh3e4Juj7btQaea22b3c7H4b2w62coOWwfH9hmyzn8Xw/YthCGPGsXcNckoNR58cg7gpaRQZQ7DNv3HaFV9Em1YEJjIeUu+1NRfrx8QFwvWP42pL4Dgx6t/aDrs++egdLDMOsx2zEb2qT6z03/Gj6/G0oP2cehTW1i8PKB5F/ZpqDw5md+DaXUGXnkHUGvlhEA/LR535kPrFw2OLI1JF1ha8uXl7owugZmxxLbdNPjNigvgll/Pv2xB7bZcs8lh+2cjvn/sJU+o9rA9W/bdX1bDbQdur//GYY9p0lAqRrgkXcEiVHBNAsPYGFGHmP7tKj+E1PGwYc3wIbpOt+gOoyBec9AcIxtvgltajvju99iS3tUtmOJLelc4UyygY3tEo7dboHhL9R8/4JS6hiPvCMQES5JiuKnzXmn9hOcSevBtvDYsgmuC64h2TIfti+EAQ/ZUTyX/BEiWttx/mWV1iE6sM1+8w+PhxvfsxP82g6BEa/ANa9qElDKxTwyEQBckhTNweJy1mTnV/9JXl7Q6y7IWgo7XL6yZv3mqLB3A+HxdrIW2A/04c/D/i3wRn9nQbcDMHm0Pf7mKdBpJAx4GK59HXrcqqUdlKoFHpsI+rWOBGBRZt65PbHbzRAYAe8MhWn32g81ZRljl/6c/Tj8txPsXAkDx9sJXEe1HgQ3fWg7ez+/C57vAPsy4KYPbF+AUqrWiTHnveCXWyQnJ5vU1JopUjr85QWE+Pvwyd19z+2JB3fZkhQr3oGKMrv+cd/7oFm3E48zxt49rJ5svxlf+nCNxF0nHM6FQzvtcNr9W2HHYtvOf3i3/ZBvc4VNmh2urvpbvcMB6TPsgvA9boOuo2v/GpTyICKywhiTXNU+j+wsPuqSNlFMXLSVIyXlBPufw19FWFMY+ixc8gD89H+w4l07u7Vlf4jvDeXFtpbN1h9s9UrxtuUOYjtDu6Euux4ASo/AV3+wnbEX+uF6eK8t3dCk46mvv+aTE48Nj4fE/tDiYugwAoKjOCMvL1vXqeM1FxajUuqCnfWOQES8gfuNMf+tnZDOrCbvCBZk5HLr28t4545eDGofc/4vVFwAK96z324P7QSfQNscEtPBjnppNxTeG2G/Lf92ydk/JKvDUQFbvrflMCp3pn55L6yaZH/vPtbW3Dld4TRHBWyeD2un2Hj7/g6i29o7mZXvw+zHbNmGNlfA5U+CTwB8civkbYSLf2fnVoTEQnicTY5KqTrrTHcE1WoaEpFlxpiUGo/sPNRkIiguq+Cip2YztncLnri649mfcDZH/y6ragrZsw4mDLQ1jW6adOox+zbbMfRdbjh7B2nJIZh6J2TMghaXwOgPbYXNtVPhszvtJCtvX/jxPzYZXf0yxPc6/vwj+2Dp/2DlBzY5BTSyFTnLi21nbVG+HfHTsj+0uhR+esUmO58Am1Suf9u29Sul6o2aaBpaJCKvAJ8AR45uNMasrIH43CbA15uUlhHn3mF8Omf6AG/SyQ6LnPOE7Vvo+cvjx6d9BtPvt7Nvt/4Av3jxxMlsleXvsKNsctPtaJxVk2x9pGH/gRkP2Kapyx6ziSChD3w+Dt6+3NbiSbkL9q6HZW9BWSG0vcq247cdAsUHYclrtjY/xo7u6fmr4yOlFr0EuRth2L/tHYBSqsGo7h3B/Co2G2PMZVVsd6mavCMAeP2HzTz7TTpLHh1MbLiLx6s7Kuykqe2LILq9/RDOz7I1jeJ726aWxa9A+1/Yb90lB23V020LbZIoK7J19h0OGPWu7QfInGeba8qO2EXV71kIjRKOn7PkEKz+CJa+bovniRd0vh76P3S8wmplJc5SDv6hrv27UErVqgtuGqpLajoRbM49zODnf2D80Pbcc2ktlJguPWKbcFZ/aEcUgR1xdPlf7bf4Jf+Db8dDWHM4tAuMw3bEBkfZGvqBjWHwk7Yt/6icFbYDd+Cfod2Qqs/rcMCOn2ybvg7TVMrj1EQfQTjwJDDAuekH4GljTMHpn+UaNZ0IAEa9vpjcwyV89+ClSG1OYMrLsN/ym1504va1U+1IpBYX21E1MR11YpVS6oKcKRFUd0LZROAQMMr5cxB4p2bCc7/RKfFszTvCki37a/fEUUmnJgGwHcZ3fAWD/mz7FjQJKKVcqLqJoLUx5kljzBbnz1NAK1cGVpuGdWlKWIAPHy/f4e5QlFKq1lU3ERSJyCVHH4hIP6DINSHVvgBfb67t3pxv0naTX6glppVSnqW6ieAe4FUR2SYi24BXgLtdFpUbjE5JoLTcwecrc9wdilJK1aqzJgIR8QLaGWO6AhcBFxljuhtj1lTjuUNEZKOIZIrI+Cr23yMia0VktYgsFJEamNV1fjo0DaNrfCM+Xr6D+jaSSimlLsRZE4ExxgH8yfn7QWPMweq8sLM0xavAUKAjMKaKD/rJxpguxphuwL+BF84l+Jo2plc8m/YcZu6Gve4MQymlalV1m4bmishDIhIvIhFHf87ynBQg09m5XAp8DJxQYeykpBIMuPWr+MjuzenQNIw/TlnN1rwjZ3+CUko1ANVNBDcB9wI/AiucP2cbzN8cyKr0ONu57QQicq+IbMbeEdxf1QuJyDgRSRWR1Nzc3GqGfO4CfL2ZcGtPfLyEce+ncrik3GXnUkqpuqK6fQRjjTGJJ/3UyPBRY8yrxpjWwCPAY6c5ZoIxJtkYkxwdHV0Tpz2t+IggXrm5B5tzD/PglNWUVzhcej6llHK36vYRvHIer50DxFd6HOfcdjofAyPP4zw1rl+bKP48rAOz1u2h+zNzuPuDVD5cup0yTQpKqQaoutVH54nI9cDnpvpDapYDSc4bENIAAB6VSURBVCKSiE0Ao4GbKx8gIknGmAznw+FABnXEnZckEh8RxHcb9rIwM49Z6/aQX1jGvYO0To9SqmGpbiK4G/gDUCEixYBgq4+Gne4JxphyEbkPmAV4AxONMetE5Gkg1RgzHbhPRC4HyoADwO0XcC01SkS4qlMsV3WKxRjDqDcWM331Tk0ESqkGp7qJIBy4BUg0xjwtIgnAWZekMsbMBGaetO2JSr///hxidRsR4RcXNePJ6evI2HOIpCZaolkp1XBUd9TQq0AfYIzz8SHOr9+g3hraJRYvgRlrdrk7FKWUqlHVTQS9jTH3AsUAxpgDgJ/LoqqDYkID6J0YyVdrdurMY6VUg1LdRFDmnClsAEQkGvC4ITS/6NqULblH2LDrkLtDUUqpGlPdRPAy8AUQIyJ/BxYC/3BZVHXU0M5N8fYSZqzZ6e5QlFKqxlQrERhjPsTWG/onsAsYaYz51JWB1UURwX5c3Fqbh5RSDUt17wgwxqQ7ZwG/YozZ4Mqg6rKrL2pG1v4i1mTX+iqdSinlEtVOBMq6qlMs/j5ePDdro5afUEo1CJoIzlF4kC/PXNOZhZl5/GNmurvDUUqpC1bdCWWqklG94lm/6yATF22lQ9NQbkyOP/uTlFKqjtI7gvP02PAO9GsTyV++SGPljgPuDkcppc6bJoLz5OPtxStjetAk3J/7Plypi94rpeotTQQXoHGwH6/e3IPcwyU89OkaHVKqlKqXNBFcoIviGjF+aAfmbtjDO4u2uTscpZQ6Z5oIasCv+rXk8g5N+Oc3G1i6ZZ+7w1FKqXOiiaAGiAj/ufEiYkIDuGnCEm6buIxFmXnaVKSUqhekvn1YJScnm9TUVHeHUaWCwjImLd3OO4u2kXe4hJhQf9o3DaNdkxBGdm9Op2bh7g5RKeWhRGSFMSa5yn2aCGpecVkF03/eyZIt+9i4+xAZew8THujLT+Mvw9dbb8KUUrXvTIlAJ5S5QICvN6OS4xnlnGg2b8Me7nwvlXkb9jKkc6ybo1NKqRPp19NacGnbaJqGB/DRsh3uDkUppU6hiaAW+Hh7cWNyPD9m5JJ9oNDd4Sil1Ak0EdSSm3rZZqIpy7PcHIlSSp1IE0Etad4okIFto/kkNUvLVyul6hRNBLVoTEoCew6WMH9jrrtDUUqpYzQR1KLL2scQE+rPO4u24nDUr2G7SqmGSxNBLfLx9uK3A1vz0+Z9PDVjnc48VkrVCS5NBCIyREQ2ikimiIyvYv8fRWS9iKwRkXki0sKV8dQFt1/ckrv6J/Le4u28MGeTu8NRSinXTSgTEW/gVeAKIBtYLiLTjTHrKx22Ckg2xhSKyG+AfwM3uSqmukBE+POwDhwsKuf/vsukoKiMFpHBCNAqOpiB7WLcHaJSysO4cmZxCpBpjNkCICIfA9cAxxKBMWZ+peOXAGNdGE+dISL847oulJRX8P7i7Sfse+u2ZC7v2MRNkSmlPJErE0FzoPKg+Wyg9xmOvxP4pqodIjIOGAeQkJBQU/G5lbeX8OLo7jw9sjPGAWUOB7e+vYzxn6/h24QBRIX4uztEpZSHqBOdxSIyFkgGnqtqvzFmgjEm2RiTHB0dXbvBuVhYgC/hQb5Ehfjz4k3dOFhczvjPdLUzpVTtcWUiyAHiKz2Oc247gYhcDvwFGGGMKXFhPHVeu9hQHhnSnrkb9vKxzkBWStUSVyaC5UCSiCSKiB8wGphe+QAR6Q68gU0Ce10YS73xy4tb0q9NJE9OX8dfp68jJ7/I3SEppRo4lyUCY0w5cB8wC9gATDHGrBORp0VkhPOw54AQ4FMRWS0i00/zch7Dy0t4aXR3rr6oGZOWbOfSf8/nwSk/s+dgsbtDU0o1ULowTR2Wk1/E2wu28uHS7fh5e/Gnoe25JSUBLy9xd2hKqXpGVyir57blHeGxaWkszMzjorhwerWMIDYsgPiIIC7vEIOPrnqmlDoLTQQNgDGGaatzeG3+ZrIPFFFUVgHAjT3j+PcNFyGidwlKqdPTpSobABHh2u5xXNs9DmMMB4vLefPHLbwyP5OEiCB+NzjJ3SEqpeopTQT1kIgQHujLg1e2ZWd+Ec/P2URcRCBXdIwlddt+VmflM7Jbc1pGBbs7VKVUPaCJoB4TEZ69/iJ2FRTz0KdrgDVUOMtbz1y7iy/vvYRAP2/3BqmUqvM0EdRzfj5evD62J099tY7YsAD6to6ksLSCuz9YwTNfr+cf13Zxd4hKqTpOE0EDEB7kywujup2w7e4BrXjjxy30bxPF0C5N3RSZUqo+0HGHDdSDV7aja1w4j3y2hu37jrg7HKVUHaaJoIHy8/Hi/8b0wADDXlrAGz9sprTc4e6wlFJ1kCaCBiwhMoivfncJfVtH8s9v0hny0o9MW5VDYWm5u0NTStUhOqHMQ8xP38szX61nS94Rgvy8uapTLH1bR9IsPJCmjQJoERGkM5SVasB0QpliUPsYLm0bzbJt+/lydQ5fr9nFF6uOVwXvkdCIyXf1IcBXh5sq5Wn0jsBDlVU42JlfxK6CYn7Oyuef36Qztk8Cfxupw02Vaoj0jkCdwtfbixaRwbSIDKZPq0j2F5byxg9bSG4Rwcjuzd0dnlKqFmkiUAA8fGU7Vu3I59HP19I42I+CojLSdx2kSVgAt/VtoUXtlGrANBEoAHy8vXhlTHeGvbyQ2ycuA8BLwGFgV0Ex44e2d3OESilX0USgjokJC+Cju3qTtrOAdk3CaB0TzDNfref1HzYTGuDDvYPauDtEpZQLaCJQJ0hqEkpSk9Bjj58e0ZnDxeU8N2sjxWUVdGoWhr+PN6EBPiTFhBIe5HvW19x/pJSHPv2ZPw1pR/vYMFeGr5Q6D5oI1Bl5eQnP3diVwtIK/u+7zFP2x4YF0C2+Ec+M7Ex0qH+Vr/HcrI18l74XHy9hwm1VDlpQSrmRJgJ1Vr7eXrxxa0+27SukqLSCkvIK8gvL2LTnEBt3H2Jm2i7GvLmEyXf1JiY04ITnpuUU8PHyHTQJ82f2+j1k7j1Em5jQ05xJKeUOOpVUVYuIkBgVTMdmYXRPaMyg9jHcfWlrXripG+/+MoWd+UWMmbCEvQeLjz3HGMOT09cRGezHlLv7EuDrxes/bHHjVSilqqKJQF2wPq0iefeXKewuKOamCUuO1TOatjqHFdsP8Kch7WkRGczoXglMW5XDzvwid4eslKpEE4GqESmJEbz3qxTKHQ4e+GQ1yX+byxNfrqNrfCNu6BEHwF0DWgHw1oKt7gxVKXUSTQSqxiS3jOCHhwYx5e6+XNOtGVEh/vztms54ednJaM0bBXJNt+Z8tGwH+4+UujlapdRRWmtI1aqMPYe46sUfad44kEeHdmBo51idtaxULThTrSGX3hGIyBAR2SgimSIyvor9A0RkpYiUi8gNroxF1Q1JTUL54M7eBPn68NsPVzLqjcW8Oj+TDxZvY9qqHL1TUMoNXHZHICLewCbgCiAbWA6MMcasr3RMSyAMeAiYboyZerbX1TuChqG8wsGnK7L575xN7D1Ucmx7fEQgk3/dh/iIIDdGp1TD467qoylApjFmizOIj4FrgGOJwBizzblP11D0MD7eXoxJSWB0r3hKyh0cLiln0+5D3DNpBaMnLOHDX/emZVQwh0vKmb1uN42D/RjYNlqbkZRyAVcmguZAVqXH2UDv83khERkHjANISEi48MhUnSEiBPh6E+DrTVQbfz4a14exby1l1BuL6dcmim/TdlNUVgHAJW2iePLqjieUwFBKXbh6MWrIGDPBGJNsjEmOjo52dzjKhTo1C+fjcX1xGJi7YQ/X9mjOZ7/py1+v7sia7HyGvLSAhz/9mfkb91JSXuHucJVqEFx5R5ADxFd6HOfcptQZtYsN5YeHB+LtJceWzuzZIoKruzbjv3M38cXKHD5dkU2ovw8D2kbTu1UEKYkRtI0JPTZUVSlVfa5MBMuBJBFJxCaA0cDNLjyfakCC/U/9pxkZ4s/fRnbhseEd+WlzHrPS9rAgI5ev1+4CoEmYP3f1b8XNvRMI8tMyWkpVl0vnEYjIMOBFwBuYaIz5u4g8DaQaY6aLSC/gC6AxUAzsNsZ0OtNr6qghdbLsA4Us3bKfqSuyWbxlH42DfLm+RxwxYf4E+/sQGexHj4TGxIQFnP3FlGqgzjRqSCeUqQZlxfYDvDY/k/kb9+I46Z92YlQwl7SJ4k9D2hEacPZ1FE5WVFpBgK+XjlxS9ZIuXq88Rs8WjXn7jl44HIbCsgqOlJSzq6CY1G37WbJlPx8t28H6XQd5/1cpx5qffsrM49+zNvKbga25qlNsla+7fd8RRr66iKs6xfLs9RfV5iUp5XL1YtSQUufKy0sI8fehiXPhnF/3b8Vbtyfzf2O6szorn1+9u5zC0nIm/LiZsW8vZd3OAu6ZtIK3Fmzh5Lvk4rIKfjNpJflFZXy8PItvnH0SYEttT166g3kb9lxwzFn7C3nyyzSKy3Q0lKpdmgiURxnapSkvjOrK8m37GfDv7/nHzHSGdI5l8aODGdIplr99vYEnp687YWjqUzPWsX7XQV4f25OuceE8+sVa9hwsxuEwPP3Vev78xVp+++FKNu05dEGxvTwvg/cWb+ezldkXeplKnRPtI1AeaeqKbP46fR33D27DXf1bISI4HIZnv01nwo9bCAvwYfhFzYgNC+C/czfxm4GteWRIezbnHmb4ywvo1TKCJmEBTF2RzZiUBOas301UiD/T7u13bMjruThwpJQ+/5xHSbmDVlHBzP3jpToUVtUo7SNQ6iQ39Izjuu7NT/iw9fIS/jysA5e2jWbqimy+XJ1DYWkFvRMjePCKtgC0jg7hL8M78vi0NAAeuDyJ3w9O4sqOTfjlu8v517fpPHn1GQe+VWlKahYl5Q5+O7A1r32/me/S93J5xyY1c7EXwOEw5BeVERHs5+5QlAtpIlAe63TfuPu1iaJfmygKS8tZlLmPlJYR+Hgfb0Ud2zuB7P2FtIgM5ubetuTJoPYx3HFxS95ZtI3kFhEM63Jiee3ScgflDkeV8xsqHIZJS7eTkhjBH65oyxercnhr4ZZaTQTrdhaQfaDolM7yl+Zl8OaCLfzw8CCiQ/1rLR5VuzQRKHUaQX4+XFHFh7GI8OiwDqdsHz+0PUu27OPeyStp3iiQYV1iiQkNYNHmPJZt3U95heGqzrGM6RVPn1aRxxLR9xv3krW/iPFDOuDr7cUv+7XkHzPTScspoHPzcJdfZ0FRGXe8s5x9h0uY88dLaR0dcmz7xIVbKSytYPLSHfz+8iSXx6LcQzuLlaohAb7eTP3NxTx3w0W0bRLCuz9t4+8zN7BjfyE39IxjTEo8P27K5ea3ljL4hR+YuiKb8goH7y/eTpMwf67sZJPO6JQEQvx9eHPBllqJ+9lvNrDvcAn+Pt68MHvTse2TlmznUEk5STEhTFq6ndJyLRLcUOkdgVI1KMTfhxuT47kxOZ6CojKKyypoUmlG86PDOjBr3W4m/LiFhz79mf/7LoPt+wr5w+Vt8XU2P4UF+HJTr3je/Wkbw7s05cqTmmuMMdWe1FbhMEz/OYeEiCB6tog4Zf/izfv4aFkWdw9ohb+vNy/Py+Ce7AJaxwTz9sKtDGoXzR39Erl94jK+XruTa7vHXcDfjqqrNBEo5SLhgb6EB544gznA15trujVnRNdmzFm/hxfnZhDi78OYlPgTjrv70lYsysxj3AcrGNYllsd/0ZH1Ow/yyfIsFmbmMSo5nkeHtcff5/QjlH7anMfTM9aTvvsQvt7C86O6MaJrs2P7i8sq+PMXa0mICOKBy9tS7nDwweJt/HtWOoPaxbD/SCn3DmpDzxaNaR0dzDuLtjGyW3OdWe1iDoep9RFjmgiUcgMR4cpOsVzeoQnF5RWndCLHhAYw43eXMOHHLbw0L4OZa3cDEBXix8WtI3n3p22s3HGAV2/uQZCfNzPX7uLbdbs5VFyOt5dQXmFYm1NA80aBvDCqKx8vz+L+j1aRe6iEW/u0YGFmLpOW7GBr3hE+/HVvAv28AW9+O7ANf5+5gVU78klJjCC5pb2LuKNfIo9PS2PljgNV3lmomrE2u4AbXv+Jz35zca30Dx2l8wiUquO25B7mk+VZ9GjRmMvax+Dr7cW3abt5eOrPVDgMJeUOKhyGpJgQ4hoHUu4wlFcYLkmK4s5LEgnw9aa4rIIHPl7Nt+t2E+TnTWFpBaH+Powb0IrfDT7eCVxcVsGg/3zProJi3v9VCgPa2vU/CkvL6fOPefRvG82rN/c4Y7w5+UU0DQvQeRDn4S9frOXDpTu4/7I2/PHKdjX62lp0TqkGKGt/Ic/P3kizRoGM6NaM9rFhZzy+wmF45btMcvILGdI5ln5toqpsWvoufQ8/bMzlryM6ndAM9I+ZG3h74Vb+e9OJTUyVvbVgC3/7egOdmoXxpyHtGZAUpU1J1VRSXkHK3+dRUFRGt/hGTLu3X42+viYCpdQFKygs4673U1m2bT/3D07iD5cnnfAh//bCrTzz1Xr6tYlk+75Csg8UcXHrSH7VL5EBbaPx8/GivMLBN2m7+XRFNj0TGnPfZW3w1jsHAL5N2809k1bQI6ERq7PyWfn4FTQKqrmJfDqzWCl1wcKDfPng1yn85Ys0Xp6XQfqug1zVKZbmjQP5OSuff36TztDOsbw8pjsOY/ho6Q5emb+ZX7+fSuMgXy7v0IQlW/eRtb+IqBB/ftyUy5It+3hpTDdiQk9cK8IYw9a8I4QG+NboRLY9B4uZvHQHY/u0qHMT5L5YlU1UiD+PDGnPTROW8NPmfQzr0rRWzq2JQClVbf4+3jx3w0W0iQnhP7M2Mnv98aqrR5PA0WGwd/RL5JY+LfhxUy5frMphxpqddGwaxmPDO3JFhyZMXZnNE1+mMfzlhdzapwVhAT6EBPiyac8h5qzfw9a8IwT7efPCTd1OWx78XMxet5tHPlvDgcIy5qXv4eNxfQmpYiU8d8gvLOW79L3c1rclPVs0JtTfhwUZubWWCLRpSCl1XorLKtiZX0ROfhGFpRXHOrJPp6r5D+m7D/L7j1azsVLlVl9voW/rKC5rF80Xq3L4ObuA+wcn8cDgpCo7oCschoy9h1i1I5/1Ow+Sk1/EzvwiCorKaBkZTLvYUA4Wl/H5yhw6NQtjdK94/jpjPRe3juTt23vh53N+82rTcgoAamR0z6Ql23lsWhpf/e4SOjcP5+4PUknLOcjCRwYhIpRXOBj/+VruuLjleZ9Pm4aUUjUuwNebVtEhtHKWpDibqjqN28eGMesPAygtd3C4pJxDxWVEhvgf+6Y+OiXhWFPU1NQsKozhUHE5ZRUOAny88ff1oqi0giOltmx4qL8PcRFBxDUOomNTH7bkHeHT1CwKyyoYN6AVD17ZFn8fb/x9vfnT1DU88tkanr+x6zmPcPpxUy6/fj8Vh8Pwl+EduOPilhfUKf7FqhySYkLo1Mx2+PdPimbWOntX1Co6hImLtjJ1RTYD20W7ZFipJgKllNv5+XgR4eN3SpXTAF9v/nPjRfRq2ZgFGXmE+PsQEuCDr7cXpeUOissr8PP2omt8ON3jG9MiMuiUD2SHw1BUVnFsRTqAUcnx7Cko5vk5m1iQkcugdjEM7hBD2yahxIQFEOznzebcI3y/cS+LN+8jMSqYO/sn0jQ88FgSaB0dQvNGgTw1Yz1rsgv4x7VdnPMxqs8Yw3fpe1mx/QB/GtLuWOwDkuyw3QUZeXiJ8PzsTVzRsQnDXdRUpE1DSimPZIzhm7TdfJO2m+837uVQcfmxff4+XpQ4ayu1iAwi+0ARXgJXdoplzvo9tI4OYfKvexMe6Mtr32fy/JxNBPp60zQ8gKbhgXRoGsrYPi1oERl87DU37DrI6qx8/H28CPLzZu+hEt5fvJ3MvYeJDQtg+n39iKlUjuTS5+bTOjqEIyXlrN91kLl/vPSEciXnSoePKqXUGZRVOPg5K5+sA4XsOVhC7qESWkUHMyApmviIILL2F/LWgi18vDyLVs4k0LjS3cvizfuYs34Puw8WsTO/mHU7Cyh3GK7o0ISu8Y2Y8fNO0nefuoJdl+bh3HFxS37Rtekpczoem7aWSUt2APDsdV0YnZJwQdeoiUAppWrAweIy/Ly9zroK3Z6Dxby/eBsfLt1BfmEZXeMbcV335gxqF4PDGApLK/D1FtrEhJy2b2HWut3c/cEK+raKZPJdvS94Yp4mAqWUcoOi0gryi0ppGh54zs8tLqvgX9+mc+clicQ1DrrgWHTUkFJKuUGgnzeBfueeBMB2lJ/Psqfnw6UL04jIEBHZKCKZIjK+iv3+IvKJc/9SEWnpyniUUkqdymWJQES8gVeBoUBHYIyIdDzpsDuBA8aYNsB/gX+5Kh6llFJVc+UdQQqQaYzZYowpBT4GrjnpmGuA95y/TwUGi5YqVEqpWuXKRNAcyKr0ONu5rcpjjDHlQAEQ6cKYlFJKnaReLF4vIuNEJFVEUnNzc90djlJKNSiuTAQ5QOWFWOOc26o8RkR8gHBg38kvZIyZYIxJNsYkR0dHuyhcpZTyTK5MBMuBJBFJFBE/YDQw/aRjpgO3O3+/AfjO1LeJDUopVc+5bB6BMaZcRO4DZgHewERjzDoReRpINcZMB94GPhCRTGA/NlkopZSqRfVuZrGI5ALbz/PpUUBeDYZTX3jidXviNYNnXrcnXjOc+3W3MMZU2bZe7xLBhRCR1NNNsW7IPPG6PfGawTOv2xOvGWr2uuvFqCGllFKuo4lAKaU8nKclggnuDsBNPPG6PfGawTOv2xOvGWrwuj2qj0AppdSpPO2OQCml1Ek0ESillIfzmERwtrURGgIRiReR+SKyXkTWicjvndsjRGSOiGQ4/2zs7lhrmoh4i8gqEfnK+TjRucZFpnPNC7+zvUZ9IyKNRGSqiKSLyAYR6esh7/UfnP++00TkIxEJaGjvt4hMFJG9IpJWaVuV761YLzuvfY2I9DjX83lEIqjm2ggNQTnwoDGmI9AHuNd5neOBecaYJGCe83FD83tgQ6XH/wL+61zr4gB27YuG5iXgW2NMe6Ar9vob9HstIs2B+4FkY0xnbNWC0TS89/tdYMhJ20733g4Fkpw/44D/nevJPCIRUL21Eeo9Y8wuY8xK5++HsB8MzTlx3Yf3gJHuidA1RCQOGA685XwswGXYNS6gYV5zODAAW6YFY0ypMSafBv5eO/kAgc5ClUHALhrY+22M+RFbdqey07231wDvG2sJ0EhEmp7L+TwlEVRnbYQGxbnsZ3dgKdDEGLPLuWs30MRNYbnKi8CfAIfzcSSQ71zjAhrm+50I5ALvOJvE3hKRYBr4e22MyQH+A+zAJoACYAUN//2G07+3F/z55imJwKOISAjwGfCAMeZg5X3O6q4NZsywiPwC2GuMWeHuWGqZD9AD+J8xpjtwhJOagRraew3gbBe/BpsImwHBnNqE0uDV9HvrKYmgOmsjNAgi4otNAh8aYz53bt5z9FbR+eded8XnAv2AESKyDdvkdxm27byRs+kAGub7nQ1kG2OWOh9PxSaGhvxeA1wObDXG5BpjyoDPsf8GGvr7Dad/by/4881TEkF11kao95xt428DG4wxL1TaVXndh9uBL2s7NlcxxjxqjIkzxrTEvq/fGWNuAeZj17iABnbNAMaY3UCWiLRzbhoMrKcBv9dOO4A+IhLk/Pd+9Lob9PvtdLr3djpwm3P0UB+goFITUvUYYzziBxgGbAI2A39xdzwuusZLsLeLa4DVzp9h2DbzeUAGMBeIcHesLrr+gcBXzt9bAcuATOBTwN/d8bngersBqc73exrQ2BPea+ApIB1IAz4A/Bva+w18hO0DKcPe/d15uvcWEOyoyM3AWuyIqnM6n5aYUEopD+cpTUNKKaVOQxOBUkp5OE0ESinl4TQRKKWUh9NEoJRSHk4TgVK1SEQGHq2QqlRdoYlAKaU8nCYCpaogImNFZJmIrBaRN5zrHRwWkf86a+HPE5Fo57HdRGSJsxb8F5XqxLcRkbki8rOIrBSR1s6XD6m0jsCHzhmySrmNJgKlTiIiHYCbgH7GmG5ABXALtsBZqjGmE/AD8KTzKe8DjxhjLsLO7Dy6/UPgVWNMV+Bi7ExRsFVhH8CujdEKWytHKbfxOfshSnmcwUBPYLnzy3ogtsCXA/jEecwk4HPnugCNjDE/OLe/B3wqIqFAc2PMFwDGmGIA5+stM8ZkOx+vBloCC11/WUpVTROBUqcS4D1jzKMnbBR5/KTjzrc+S0ml3yvQ/4fKzbRpSKlTzQNuEJEYOLZWbAvs/5ejFS5vBhYaYwqAAyLS37n9VuAHY1eIyxaRkc7X8BeRoFq9CqWqSb+JKHUSY8x6EXkMmC0iXtgKkPdiF39Jce7bi+1HAFsS+HXnB/0W4JfO7bcCb4jI087XuLEWL0OpatPqo0pVk4gcNsaEuDsOpWqaNg0ppZSH0zsCpZTycHpHoJRSHk4TgVJKeThNBEop5eE0ESillIfTRKCUUh7u/wFs2abfJAYw3wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utils import n_plot_graphs\n",
    "\n",
    "n_plot_graphs(train_log, test_log, 'loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_plot_graphs(train_log, test_log, 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'default': [(0.3174367561817169, 91.15),\n",
       "  (0.2408550163269043, 92.94),\n",
       "  (0.19958798387050627, 94.15),\n",
       "  (0.17202180874347686, 94.67),\n",
       "  (0.15257697781324386, 95.42),\n",
       "  (0.13403327289819716, 95.93),\n",
       "  (0.12190695995092392, 96.35),\n",
       "  (0.11166962240338325, 96.68),\n",
       "  (0.1068451723575592, 96.72),\n",
       "  (0.10148451241254806, 96.87),\n",
       "  (0.09294669792503119, 97.13),\n",
       "  (0.09206985440552234, 97.21),\n",
       "  (0.08847811326533556, 97.34),\n",
       "  (0.0866486031383276, 97.28),\n",
       "  (0.08762764247506857, 97.35),\n",
       "  (0.0841078143209219, 97.45),\n",
       "  (0.0851175547786057, 97.44),\n",
       "  (0.08364937973469495, 97.45),\n",
       "  (0.08336126733217389, 97.6),\n",
       "  (0.08229483855813742, 97.67),\n",
       "  (0.08305189070999622, 97.61),\n",
       "  (0.08675617944933474, 97.49),\n",
       "  (0.08619866179004311, 97.66),\n",
       "  (0.08653611945472657, 97.66),\n",
       "  (0.08704996525347233, 97.71),\n",
       "  (0.09011154256556184, 97.65),\n",
       "  (0.08908834441173821, 97.68),\n",
       "  (0.09195641261581332, 97.67),\n",
       "  (0.09835801188591868, 97.58),\n",
       "  (0.09565127716157586, 97.65),\n",
       "  (0.10143983636088669, 97.5),\n",
       "  (0.09625096426997334, 97.61),\n",
       "  (0.09865145124355332, 97.68),\n",
       "  (0.10079164826497436, 97.67),\n",
       "  (0.09752485083298525, 97.64),\n",
       "  (0.10130594804981956, 97.56),\n",
       "  (0.09941800609026104, 97.7),\n",
       "  (0.10382441838895902, 97.63),\n",
       "  (0.1043049927328946, 97.74),\n",
       "  (0.1006747594457469, 97.81),\n",
       "  (0.1021385541681666, 97.76),\n",
       "  (0.12474274096649605, 97.26),\n",
       "  (0.10683206714011613, 97.67),\n",
       "  (0.10583438282398275, 97.7),\n",
       "  (0.10550240073736059, 97.63),\n",
       "  (0.10596512191055808, 97.7),\n",
       "  (0.1348733474381268, 97.03),\n",
       "  (0.1132875257441774, 97.65),\n",
       "  (0.11066383460118086, 97.57),\n",
       "  (0.11038878046975005, 97.65),\n",
       "  (0.11059914881956065, 97.68),\n",
       "  (0.13088734302741942, 97.51),\n",
       "  (0.11397756781261414, 97.71),\n",
       "  (0.11266686592538608, 97.73),\n",
       "  (0.11259965154046658, 97.78),\n",
       "  (0.11249619457673252, 97.76),\n",
       "  (0.11362188371699013, 97.74),\n",
       "  (0.1157494268632996, 97.78),\n",
       "  (0.12704110071733593, 97.55),\n",
       "  (0.12165551248661359, 97.63),\n",
       "  (0.12060295317389828, 97.69),\n",
       "  (0.12043018790443602, 97.64),\n",
       "  (0.1198599313739658, 97.68),\n",
       "  (0.11939414357452188, 97.68),\n",
       "  (0.12011243062507128, 97.69),\n",
       "  (0.12699678074902768, 97.6),\n",
       "  (0.12534576982082218, 97.6),\n",
       "  (0.12493657470518955, 97.65),\n",
       "  (0.12336439371943707, 97.65),\n",
       "  (0.12396234830857138, 97.67),\n",
       "  (0.12376319458977741, 97.66),\n",
       "  (0.12349264438311802, 97.67),\n",
       "  (0.1250040607135321, 97.69),\n",
       "  (0.12463738435787963, 97.7),\n",
       "  (0.12533142890234303, 97.76),\n",
       "  (0.13645912560682627, 97.56),\n",
       "  (0.1280175062877228, 97.61),\n",
       "  (0.12755473315555718, 97.7),\n",
       "  (0.12753154725208296, 97.71),\n",
       "  (0.12737654682889843, 97.71),\n",
       "  (0.1272462049060192, 97.71),\n",
       "  (0.12781923115836544, 97.74),\n",
       "  (0.12770178974496374, 97.73),\n",
       "  (0.12916453424698046, 97.76),\n",
       "  (0.14426586357020715, 97.52),\n",
       "  (0.13520739778576535, 97.6),\n",
       "  (0.13196809742402693, 97.72),\n",
       "  (0.13134062389392348, 97.75),\n",
       "  (0.13129250562524322, 97.77),\n",
       "  (0.13160122780013045, 97.76),\n",
       "  (0.1321605735153251, 97.73),\n",
       "  (0.13283878679778172, 97.76),\n",
       "  (0.13321949630745183, 97.68),\n",
       "  (0.13443850733792037, 97.72),\n",
       "  (0.13507493954548883, 97.75),\n",
       "  (0.17211854095342569, 97.24),\n",
       "  (0.14315782194677548, 97.62),\n",
       "  (0.14204373951747876, 97.63),\n",
       "  (0.14133158570153864, 97.66),\n",
       "  (0.1411395876030241, 97.68),\n",
       "  (0.14078128235173282, 97.7),\n",
       "  (0.14009814556245037, 97.64),\n",
       "  (0.1403497707163042, 97.68),\n",
       "  (0.139773422365849, 97.71),\n",
       "  (0.13906804139974263, 97.75),\n",
       "  (0.1393492412263504, 97.73),\n",
       "  (0.17142999033533707, 97.45),\n",
       "  (0.1473200892120607, 97.53),\n",
       "  (0.1461585929298366, 97.6),\n",
       "  (0.14631286887746323, 97.64),\n",
       "  (0.14621311807046186, 97.68),\n",
       "  (0.14659596977271577, 97.69),\n",
       "  (0.14625792075854777, 97.69),\n",
       "  (0.14573254285615095, 97.69),\n",
       "  (0.14587822556773752, 97.72),\n",
       "  (0.14531504293640754, 97.72),\n",
       "  (0.1457875056716395, 97.75),\n",
       "  (0.14548622456284938, 97.7),\n",
       "  (0.14557845242074435, 97.73),\n",
       "  (0.1657262527248844, 97.31),\n",
       "  (0.1563853351280668, 97.57),\n",
       "  (0.15489814485680944, 97.57),\n",
       "  (0.15387728488768626, 97.6),\n",
       "  (0.15288287588927324, 97.63),\n",
       "  (0.15218913954736635, 97.66),\n",
       "  (0.15124780752048647, 97.68),\n",
       "  (0.15076691742090867, 97.67),\n",
       "  (0.14971178036833388, 97.71),\n",
       "  (0.1497238424717979, 97.73),\n",
       "  (0.14982042478569346, 97.75),\n",
       "  (0.16154054302941048, 97.43),\n",
       "  (0.15998848000436136, 97.49),\n",
       "  (0.15678600371027496, 97.51),\n",
       "  (0.15553003753141073, 97.55),\n",
       "  (0.154512679439955, 97.58),\n",
       "  (0.15365584778360664, 97.59),\n",
       "  (0.1528387894114556, 97.59),\n",
       "  (0.1525550918306687, 97.64),\n",
       "  (0.1523962933536699, 97.63),\n",
       "  (0.15159724559804416, 97.64),\n",
       "  (0.15132456580324175, 97.7),\n",
       "  (0.1534881519235254, 97.73),\n",
       "  (0.15132976308570414, 97.75),\n",
       "  (0.19643462366297082, 97.2),\n",
       "  (0.1660805661917529, 97.46),\n",
       "  (0.16524749024301671, 97.52),\n",
       "  (0.1617933844011285, 97.54),\n",
       "  (0.16062031421742795, 97.56),\n",
       "  (0.1596596373996475, 97.6),\n",
       "  (0.1591210225632287, 97.66),\n",
       "  (0.15835135342311804, 97.66),\n",
       "  (0.15807921766064445, 97.63),\n",
       "  (0.15743369475171895, 97.69),\n",
       "  (0.15768518704157758, 97.63),\n",
       "  (0.15758230148359142, 97.66),\n",
       "  (0.1579990751093348, 97.7),\n",
       "  (0.157624054677202, 97.71),\n",
       "  (0.1596212602303068, 97.73),\n",
       "  (0.16097528977935982, 97.67),\n",
       "  (0.2431921171220938, 96.81),\n",
       "  (0.17411993358605415, 97.53),\n",
       "  (0.17209540880280683, 97.56),\n",
       "  (0.17110105017845417, 97.55),\n",
       "  (0.17065478411180512, 97.58),\n",
       "  (0.17031535226290925, 97.6),\n",
       "  (0.169922081223017, 97.64),\n",
       "  (0.16970798212881982, 97.65),\n",
       "  (0.16912995969070052, 97.64),\n",
       "  (0.1686385127331412, 97.67),\n",
       "  (0.16854604526287922, 97.67),\n",
       "  (0.16846443347051263, 97.67),\n",
       "  (0.16824678821476263, 97.65),\n",
       "  (0.1683319109473131, 97.64),\n",
       "  (0.16893864409559828, 97.66),\n",
       "  (0.16831071165793618, 97.69),\n",
       "  (0.16874355758268245, 97.74),\n",
       "  (0.2128964342495698, 97.14),\n",
       "  (0.1787127176314346, 97.56),\n",
       "  (0.17380536983323272, 97.59),\n",
       "  (0.17366709755586224, 97.65),\n",
       "  (0.17337323871068927, 97.64),\n",
       "  (0.17345572167966597, 97.65),\n",
       "  (0.17319058955441027, 97.66),\n",
       "  (0.17287846620074912, 97.68),\n",
       "  (0.17300884617075832, 97.68),\n",
       "  (0.17309888598785125, 97.7),\n",
       "  (0.1729693388556373, 97.65),\n",
       "  (0.17268257201036205, 97.65),\n",
       "  (0.1732385523789262, 97.61),\n",
       "  (0.17295002610864577, 97.6),\n",
       "  (0.17249198384687026, 97.62),\n",
       "  (0.17272458312825753, 97.6),\n",
       "  (0.17378547816112805, 97.64),\n",
       "  (0.17472338384553765, 97.67),\n",
       "  (0.27520402105532793, 96.68),\n",
       "  (0.19589111400238868, 97.47),\n",
       "  (0.18764880710129656, 97.64),\n",
       "  (0.1850516128293989, 97.62),\n",
       "  (0.18431544958563004, 97.61),\n",
       "  (0.18336651032001355, 97.63)],\n",
       " 'bn': [(0.27335224714279177, 92.37),\n",
       "  (0.18072722840309144, 94.81),\n",
       "  (0.13471425549983979, 96.01),\n",
       "  (0.11037491684556007, 96.78),\n",
       "  (0.09923352683186532, 96.91),\n",
       "  (0.08782985059916973, 97.24),\n",
       "  (0.08195369306653738, 97.6),\n",
       "  (0.07986643289923667, 97.53),\n",
       "  (0.07572115371227264, 97.69),\n",
       "  (0.07286905948370695, 97.82),\n",
       "  (0.07567585311606527, 97.69),\n",
       "  (0.07381484602093696, 97.83),\n",
       "  (0.07366387503296137, 97.83),\n",
       "  (0.0707863780722022, 97.88),\n",
       "  (0.07203802743405104, 97.85),\n",
       "  (0.07240043780319393, 97.9),\n",
       "  (0.0762092767773196, 97.84),\n",
       "  (0.07371568669602276, 97.88),\n",
       "  (0.0739389727730304, 97.85),\n",
       "  (0.07632224462069571, 97.94),\n",
       "  (0.07858016506386921, 97.86),\n",
       "  (0.0794275966823101, 97.8),\n",
       "  (0.08018330360632389, 97.81),\n",
       "  (0.08318903932538815, 97.68),\n",
       "  (0.08167689271494746, 97.8),\n",
       "  (0.08686854916708543, 97.7),\n",
       "  (0.082595870345179, 97.93),\n",
       "  (0.08003809624454007, 97.97),\n",
       "  (0.08288670576931909, 97.91),\n",
       "  (0.08644552683406509, 97.9),\n",
       "  (0.08385376500058919, 97.8),\n",
       "  (0.0913769377117511, 97.88),\n",
       "  (0.08886975961308927, 97.92),\n",
       "  (0.08614412095695734, 97.92),\n",
       "  (0.08566943644471467, 97.93),\n",
       "  (0.08525761605957523, 97.91),\n",
       "  (0.08534251956078225, 97.89),\n",
       "  (0.08656596762451808, 97.83),\n",
       "  (0.0872857819801662, 97.9),\n",
       "  (0.09031864331418182, 97.84),\n",
       "  (0.0947184881209163, 97.84),\n",
       "  (0.09405324387946166, 97.9),\n",
       "  (0.09155710563919274, 97.98),\n",
       "  (0.08863889652036597, 98.04),\n",
       "  (0.0936143571308814, 97.9),\n",
       "  (0.09408184163172263, 97.77),\n",
       "  (0.09905716309093404, 97.87),\n",
       "  (0.10224730436259415, 97.83),\n",
       "  (0.0972213429872878, 97.78),\n",
       "  (0.10173154183607548, 97.81),\n",
       "  (0.09812228786913328, 97.74),\n",
       "  (0.09666829072376713, 97.79),\n",
       "  (0.09782330709154194, 97.93),\n",
       "  (0.10172036489986348, 97.73),\n",
       "  (0.10019828119836748, 97.85),\n",
       "  (0.09361765732562635, 97.94),\n",
       "  (0.10174969021732685, 97.78),\n",
       "  (0.10208777317854692, 97.96),\n",
       "  (0.098344421234302, 97.96),\n",
       "  (0.09980665075206198, 97.84),\n",
       "  (0.10017468963115825, 97.9),\n",
       "  (0.10471024167995202, 97.9),\n",
       "  (0.09877768914576154, 98.08),\n",
       "  (0.09802697407340456, 97.95),\n",
       "  (0.09850532752405852, 97.81),\n",
       "  (0.0971564302473329, 97.99),\n",
       "  (0.0971219366529258, 97.81),\n",
       "  (0.0985502421190904, 97.94),\n",
       "  (0.09810199247081763, 98.04),\n",
       "  (0.10157665093806573, 97.91),\n",
       "  (0.10764629381360137, 97.73),\n",
       "  (0.10485101848412305, 97.89),\n",
       "  (0.10467576929334318, 97.89),\n",
       "  (0.10393054456976242, 97.92),\n",
       "  (0.10504130888420041, 97.91),\n",
       "  (0.10646491577776032, 97.84),\n",
       "  (0.0976895982281072, 98.01),\n",
       "  (0.11091096491486387, 97.85),\n",
       "  (0.10439552366749268, 97.82),\n",
       "  (0.11292089116322604, 97.75),\n",
       "  (0.11290658337991044, 97.81),\n",
       "  (0.10898911962059064, 97.89),\n",
       "  (0.09957490893033391, 98.0),\n",
       "  (0.10396293812356744, 98.0),\n",
       "  (0.10092974227967061, 97.93),\n",
       "  (0.09972362292421749, 98.02),\n",
       "  (0.10539420501502864, 98.03),\n",
       "  (0.1048713115063787, 98.08),\n",
       "  (0.11823475576784695, 97.88),\n",
       "  (0.106535576492775, 97.98),\n",
       "  (0.10898571629845974, 97.97),\n",
       "  (0.10959519337077654, 98.0),\n",
       "  (0.10711173352490878, 97.88),\n",
       "  (0.1023591131489331, 98.03),\n",
       "  (0.10760259167159675, 97.91),\n",
       "  (0.10545356908569811, 97.99),\n",
       "  (0.11201339632821036, 97.88),\n",
       "  (0.10398775445676292, 98.01),\n",
       "  (0.10556083248361246, 98.09),\n",
       "  (0.10972656305919809, 97.97),\n",
       "  (0.10723717194689379, 97.86),\n",
       "  (0.1034068761518749, 98.08),\n",
       "  (0.11194941983601603, 97.99),\n",
       "  (0.11065656453787233, 97.94),\n",
       "  (0.11052574151011067, 97.85),\n",
       "  (0.11032528054716677, 98.08),\n",
       "  (0.11638303558574989, 97.9),\n",
       "  (0.11476039150558354, 97.91),\n",
       "  (0.1166219249306625, 97.85),\n",
       "  (0.11894225363965379, 97.73),\n",
       "  (0.10251674668541018, 98.05),\n",
       "  (0.1116416233537253, 97.96),\n",
       "  (0.11266858235540567, 97.95),\n",
       "  (0.11371608292870387, 97.82),\n",
       "  (0.10991469373488508, 97.93),\n",
       "  (0.11222499025200086, 97.98),\n",
       "  (0.1107257388112499, 97.87),\n",
       "  (0.10078174729959764, 98.03),\n",
       "  (0.11084015911591232, 97.94),\n",
       "  (0.11004185001999285, 98.02),\n",
       "  (0.10947527459146077, 97.97),\n",
       "  (0.11123458559913997, 98.0),\n",
       "  (0.1093126947328914, 98.09),\n",
       "  (0.1055625234093648, 98.02),\n",
       "  (0.1057654120151099, 98.14),\n",
       "  (0.11785714252073304, 97.87),\n",
       "  (0.11203759697098575, 98.01),\n",
       "  (0.10879628181631124, 98.07),\n",
       "  (0.11270201927554371, 98.02),\n",
       "  (0.11867458287400223, 97.84),\n",
       "  (0.1090461507025826, 97.97),\n",
       "  (0.11266975357912888, 97.98),\n",
       "  (0.1159619953360132, 97.93),\n",
       "  (0.11633577694287815, 97.97),\n",
       "  (0.11562809428051841, 97.95),\n",
       "  (0.11649843744126848, 98.03),\n",
       "  (0.11297478337743087, 98.08),\n",
       "  (0.12073050613815613, 97.94),\n",
       "  (0.11769373758977163, 98.01),\n",
       "  (0.12184223827891838, 97.95),\n",
       "  (0.11551616800333286, 98.01),\n",
       "  (0.12085219625835307, 97.77),\n",
       "  (0.12673943528568052, 97.7),\n",
       "  (0.11664650604191884, 97.93),\n",
       "  (0.10947591943286515, 98.07),\n",
       "  (0.11516386292927346, 98.0),\n",
       "  (0.1166830553950218, 98.13),\n",
       "  (0.11868441390819208, 98.17),\n",
       "  (0.11081219328342631, 98.24),\n",
       "  (0.11922684704769636, 97.98),\n",
       "  (0.11618606877664278, 98.01),\n",
       "  (0.12138707484861189, 97.92),\n",
       "  (0.11943888796481643, 98.14),\n",
       "  (0.11742892069679292, 98.12),\n",
       "  (0.11403391236879179, 98.16),\n",
       "  (0.12124214999845699, 98.08),\n",
       "  (0.11334329791580249, 98.09),\n",
       "  (0.11389502984778664, 98.15),\n",
       "  (0.1154774608896958, 97.95),\n",
       "  (0.11779674765241797, 98.01),\n",
       "  (0.12195297728041368, 97.92),\n",
       "  (0.12541550027232878, 97.86),\n",
       "  (0.12463456417923881, 98.0),\n",
       "  (0.13723623099596663, 97.63),\n",
       "  (0.12428184863387942, 97.93),\n",
       "  (0.12249620162068313, 98.02),\n",
       "  (0.11403696148318414, 98.14),\n",
       "  (0.11781560985301548, 98.0),\n",
       "  (0.11864745722241787, 97.9),\n",
       "  (0.12073656623123702, 97.97),\n",
       "  (0.1245867382743374, 97.97),\n",
       "  (0.11570856814214495, 98.11),\n",
       "  (0.11395837450340913, 97.97),\n",
       "  (0.13519131812886118, 97.7),\n",
       "  (0.12482078764324833, 97.85),\n",
       "  (0.12372384335128372, 97.93),\n",
       "  (0.12600650811683808, 98.01),\n",
       "  (0.12569060339654933, 97.92),\n",
       "  (0.11915332008526584, 98.02),\n",
       "  (0.1170504320325992, 98.12),\n",
       "  (0.1376252961810267, 97.87),\n",
       "  (0.12798958608525426, 98.0),\n",
       "  (0.12712549624409622, 97.95),\n",
       "  (0.11880101111752737, 98.09),\n",
       "  (0.12175818204668794, 98.03),\n",
       "  (0.12406774331766464, 97.84),\n",
       "  (0.11747169201679035, 98.01),\n",
       "  (0.13015998861412081, 97.87),\n",
       "  (0.14068122825679166, 97.79),\n",
       "  (0.1316903202718957, 97.98),\n",
       "  (0.12491987843353076, 97.86),\n",
       "  (0.1199936980695522, 98.02),\n",
       "  (0.12080619573110417, 98.1),\n",
       "  (0.1180578477298768, 98.09),\n",
       "  (0.12069780921621932, 98.06),\n",
       "  (0.12607496730648018, 97.93),\n",
       "  (0.1235215573518255, 97.95),\n",
       "  (0.12615045521232168, 97.99),\n",
       "  (0.1347041880489829, 97.76),\n",
       "  (0.12867175186101085, 97.87)],\n",
       " 'drop': [(0.3793333411693573, 89.96),\n",
       "  (0.28889220390319825, 91.65),\n",
       "  (0.24093779091835021, 93.15),\n",
       "  (0.20898912619352342, 94.03),\n",
       "  (0.18569868528842925, 94.5),\n",
       "  (0.16422038379907608, 95.22),\n",
       "  (0.1471345221042633, 95.56),\n",
       "  (0.13455617368221284, 96.19),\n",
       "  (0.1241792595565319, 96.48),\n",
       "  (0.11644333505630493, 96.39),\n",
       "  (0.11173490831255913, 96.66),\n",
       "  (0.10662695018947124, 96.77),\n",
       "  (0.10345325370430947, 96.83),\n",
       "  (0.09938705359995365, 96.93),\n",
       "  (0.09895673811137676, 97.1),\n",
       "  (0.09397536353468895, 97.32),\n",
       "  (0.08981091961115599, 97.35),\n",
       "  (0.09177665381133557, 97.23),\n",
       "  (0.0899552325323224, 97.4),\n",
       "  (0.09199295686855913, 97.31),\n",
       "  (0.08533838954120875, 97.44),\n",
       "  (0.08561656794697046, 97.5),\n",
       "  (0.08840457813031971, 97.47),\n",
       "  (0.08690173304602504, 97.37),\n",
       "  (0.08550659093782306, 97.64),\n",
       "  (0.08551538957357406, 97.59),\n",
       "  (0.09359588506035507, 97.42),\n",
       "  (0.08891152533851564, 97.5),\n",
       "  (0.08998540484532713, 97.62),\n",
       "  (0.09168964047431946, 97.57),\n",
       "  (0.09170072932709009, 97.39),\n",
       "  (0.09394931959807873, 97.44),\n",
       "  (0.09631842570398003, 97.29),\n",
       "  (0.0984439695239067, 97.51),\n",
       "  (0.09775350168887526, 97.48),\n",
       "  (0.09555881158169359, 97.59),\n",
       "  (0.09227608531191946, 97.57),\n",
       "  (0.10168867135364562, 97.44),\n",
       "  (0.09372842867430299, 97.6),\n",
       "  (0.09545135976262391, 97.66),\n",
       "  (0.0972679992640391, 97.64),\n",
       "  (0.103651443289686, 97.55),\n",
       "  (0.09989126068744808, 97.45),\n",
       "  (0.09700680315680801, 97.76),\n",
       "  (0.09632463642321527, 97.67),\n",
       "  (0.10677538258228451, 97.54),\n",
       "  (0.10426824150413741, 97.68),\n",
       "  (0.10873611592110247, 97.41),\n",
       "  (0.10969950310885906, 97.5),\n",
       "  (0.1031624516258482, 97.64),\n",
       "  (0.10409106642209226, 97.52),\n",
       "  (0.10623944697156548, 97.55),\n",
       "  (0.11528447615639306, 97.51),\n",
       "  (0.11417201315606944, 97.5),\n",
       "  (0.10970129203670659, 97.48),\n",
       "  (0.1140666918898467, 97.57),\n",
       "  (0.1123231088432134, 97.51),\n",
       "  (0.11800047159439418, 97.5),\n",
       "  (0.11446704704319127, 97.59),\n",
       "  (0.11836133753117174, 97.43),\n",
       "  (0.11072344399308785, 97.6),\n",
       "  (0.12043996298684506, 97.5),\n",
       "  (0.12534409122022336, 97.5),\n",
       "  (0.11292655238824664, 97.61),\n",
       "  (0.11546876985388808, 97.43),\n",
       "  (0.11794208749548998, 97.53),\n",
       "  (0.10977384782105655, 97.73),\n",
       "  (0.10875041105891578, 97.68),\n",
       "  (0.12410178570803254, 97.44),\n",
       "  (0.12021468549788697, 97.54),\n",
       "  (0.12431983985845, 97.64),\n",
       "  (0.1140325030031614, 97.68),\n",
       "  (0.11933377811419778, 97.62),\n",
       "  (0.13054783513385337, 97.52),\n",
       "  (0.1232767722923425, 97.5),\n",
       "  (0.12771832572731656, 97.5),\n",
       "  (0.12285661590655508, 97.41),\n",
       "  (0.12804639520435593, 97.52),\n",
       "  (0.1116217592404515, 97.64),\n",
       "  (0.11700257213307196, 97.79),\n",
       "  (0.12002589576881437, 97.76),\n",
       "  (0.12555025119298371, 97.47),\n",
       "  (0.12983331809057855, 97.49),\n",
       "  (0.1318254876757739, 97.39),\n",
       "  (0.1259923221537756, 97.44),\n",
       "  (0.1217821705820621, 97.64),\n",
       "  (0.11686418330818414, 97.52),\n",
       "  (0.12409391993372701, 97.49),\n",
       "  (0.12159730369321187, 97.66),\n",
       "  (0.12504133720544633, 97.53),\n",
       "  (0.13730233202107484, 97.54),\n",
       "  (0.13639328923256253, 97.52),\n",
       "  (0.12918911872131575, 97.64),\n",
       "  (0.13382027332521393, 97.63),\n",
       "  (0.14724015039093793, 97.42),\n",
       "  (0.13581703477504198, 97.55),\n",
       "  (0.13241230274150148, 97.64),\n",
       "  (0.12746035763051913, 97.63),\n",
       "  (0.14089046228615043, 97.51),\n",
       "  (0.1312072131052846, 97.67),\n",
       "  (0.1326402714990807, 97.53),\n",
       "  (0.12015714358357509, 97.76),\n",
       "  (0.14171718112548115, 97.45),\n",
       "  (0.1404574566152878, 97.59),\n",
       "  (0.13169969314694463, 97.57),\n",
       "  (0.13471445845030247, 97.71),\n",
       "  (0.13714467015373522, 97.55),\n",
       "  (0.13674522728642333, 97.47),\n",
       "  (0.1292780464672731, 97.61),\n",
       "  (0.14071097550948689, 97.62),\n",
       "  (0.13924893456199788, 97.59),\n",
       "  (0.13497179113028687, 97.54),\n",
       "  (0.12825138035389244, 97.7),\n",
       "  (0.14009105737152278, 97.36),\n",
       "  (0.138122586558474, 97.56),\n",
       "  (0.13645282797648106, 97.64),\n",
       "  (0.14756238003487523, 97.46),\n",
       "  (0.15173070350425077, 97.32),\n",
       "  (0.14835034026855573, 97.39),\n",
       "  (0.14387048632084626, 97.67),\n",
       "  (0.15442742960678588, 97.3),\n",
       "  (0.14454840672149438, 97.53),\n",
       "  (0.13793040588684236, 97.6),\n",
       "  (0.1425001747757371, 97.47),\n",
       "  (0.1472545644913509, 97.35),\n",
       "  (0.1434335864592911, 97.57),\n",
       "  (0.1464298693336197, 97.51),\n",
       "  (0.14821953712963004, 97.44),\n",
       "  (0.14765747986964925, 97.61),\n",
       "  (0.13909447293160485, 97.47),\n",
       "  (0.15761218694143753, 97.38),\n",
       "  (0.14538870114804595, 97.56),\n",
       "  (0.13777332170193987, 97.57),\n",
       "  (0.1466660697849671, 97.54),\n",
       "  (0.14764302198300647, 97.68),\n",
       "  (0.14790695066680493, 97.58),\n",
       "  (0.1602685119981572, 97.22),\n",
       "  (0.1541160758513779, 97.49),\n",
       "  (0.1556926370271358, 97.4),\n",
       "  (0.15075439696088433, 97.58),\n",
       "  (0.14825774879365053, 97.66),\n",
       "  (0.14965257303373072, 97.57),\n",
       "  (0.14893029320152537, 97.58),\n",
       "  (0.1433060560363723, 97.66),\n",
       "  (0.1510003951984603, 97.66),\n",
       "  (0.15349612067359267, 97.36),\n",
       "  (0.17030578358510393, 97.19),\n",
       "  (0.15346629062890496, 97.5),\n",
       "  (0.14497573384575044, 97.69),\n",
       "  (0.1387505068534767, 97.7),\n",
       "  (0.15252807609811717, 97.46),\n",
       "  (0.16027104553481478, 97.28),\n",
       "  (0.14987774342962365, 97.51),\n",
       "  (0.1556204304569721, 97.54),\n",
       "  (0.146349169103631, 97.69),\n",
       "  (0.15319254113025962, 97.54),\n",
       "  (0.16279489103581873, 97.47),\n",
       "  (0.16429030905100336, 97.38),\n",
       "  (0.16003637227796136, 97.4),\n",
       "  (0.1558668336954326, 97.59),\n",
       "  (0.14816035076057707, 97.67),\n",
       "  (0.15288235879628445, 97.53),\n",
       "  (0.14996513510195, 97.63),\n",
       "  (0.1535014368258804, 97.61),\n",
       "  (0.1592572866477498, 97.45),\n",
       "  (0.15205681245630331, 97.56),\n",
       "  (0.16344131367055234, 97.43),\n",
       "  (0.1724792329946198, 97.53),\n",
       "  (0.173402079770821, 97.44),\n",
       "  (0.1508006481284473, 97.61),\n",
       "  (0.15524100687204645, 97.6),\n",
       "  (0.17117501845105654, 97.51),\n",
       "  (0.1526891839611777, 97.62),\n",
       "  (0.16241930579781838, 97.63),\n",
       "  (0.15890439511203258, 97.64),\n",
       "  (0.1571562417104542, 97.49),\n",
       "  (0.1616464786403985, 97.68),\n",
       "  (0.15318122867439815, 97.61),\n",
       "  (0.16433071989231868, 97.48),\n",
       "  (0.161127632894236, 97.58),\n",
       "  (0.15447950912298838, 97.58),\n",
       "  (0.18195412834203234, 97.06),\n",
       "  (0.15833803519928624, 97.47),\n",
       "  (0.15160579771188568, 97.54),\n",
       "  (0.1479331693823362, 97.69),\n",
       "  (0.15848405157553935, 97.5),\n",
       "  (0.15682671797955808, 97.55),\n",
       "  (0.15333626545674925, 97.55),\n",
       "  (0.15516830308006466, 97.53),\n",
       "  (0.153239306516955, 97.6),\n",
       "  (0.15160156502249975, 97.57),\n",
       "  (0.14948576674761715, 97.5),\n",
       "  (0.15430355246564068, 97.63),\n",
       "  (0.14634189691481805, 97.65),\n",
       "  (0.14424572068940142, 97.61),\n",
       "  (0.16899885963163058, 97.48),\n",
       "  (0.17056311611181482, 97.47),\n",
       "  (0.15218779533909255, 97.64),\n",
       "  (0.15528037469396458, 97.57),\n",
       "  (0.1636916881903646, 97.63)],\n",
       " 'both': [(0.33549392614364626, 90.88),\n",
       "  (0.23303647756576537, 93.5),\n",
       "  (0.17584798815250396, 95.08),\n",
       "  (0.14537613562345506, 95.86),\n",
       "  (0.1269690557360649, 96.39),\n",
       "  (0.11086997808814049, 96.77),\n",
       "  (0.10312708537876605, 97.07),\n",
       "  (0.09935722566246986, 97.14),\n",
       "  (0.09614912902712822, 97.26),\n",
       "  (0.09403206126689911, 97.34),\n",
       "  (0.0899673393368721, 97.39),\n",
       "  (0.09085905553549528, 97.54),\n",
       "  (0.08614536587148905, 97.54),\n",
       "  (0.08658385862857103, 97.5),\n",
       "  (0.08795578034520149, 97.42),\n",
       "  (0.08409650317281485, 97.69),\n",
       "  (0.08253519524186849, 97.5),\n",
       "  (0.08728679673150182, 97.59),\n",
       "  (0.0821026804920286, 97.7),\n",
       "  (0.08952597560826689, 97.59),\n",
       "  (0.0879167425321415, 97.62),\n",
       "  (0.08761727834045888, 97.58),\n",
       "  (0.08609815297313035, 97.67),\n",
       "  (0.0944394897993654, 97.51),\n",
       "  (0.08809013307318092, 97.61),\n",
       "  (0.0929915121819824, 97.61),\n",
       "  (0.09335160992220044, 97.56),\n",
       "  (0.08768213437348604, 97.75),\n",
       "  (0.0910947785618715, 97.63),\n",
       "  (0.0945078617874533, 97.56),\n",
       "  (0.08926525406166912, 97.57),\n",
       "  (0.09354550411105156, 97.65),\n",
       "  (0.09266457475172356, 97.65),\n",
       "  (0.0916108170416206, 97.81),\n",
       "  (0.09265468589961529, 97.75),\n",
       "  (0.09683171802004799, 97.53),\n",
       "  (0.09424102020021528, 97.68),\n",
       "  (0.09399008403448388, 97.63),\n",
       "  (0.09935411757156253, 97.66),\n",
       "  (0.09717161879246124, 97.72),\n",
       "  (0.10322457899795845, 97.76),\n",
       "  (0.10045028796754778, 97.62),\n",
       "  (0.09584553367109037, 97.78),\n",
       "  (0.10017592492906842, 97.75),\n",
       "  (0.09410508261974901, 97.9),\n",
       "  (0.09590300747314467, 97.77),\n",
       "  (0.10071917529399507, 97.78),\n",
       "  (0.09650772399980342, 97.72),\n",
       "  (0.1067266507643275, 97.65),\n",
       "  (0.11016605165748625, 97.62),\n",
       "  (0.10877084080977366, 97.77),\n",
       "  (0.10271179773791228, 97.72),\n",
       "  (0.10939402077640407, 97.72),\n",
       "  (0.10621246268339456, 97.6),\n",
       "  (0.10536737115867435, 97.71),\n",
       "  (0.09937862244899152, 97.77),\n",
       "  (0.1083602947279578, 97.73),\n",
       "  (0.10842888818755746, 97.73),\n",
       "  (0.1112981179846567, 97.66),\n",
       "  (0.12200695775731, 97.56),\n",
       "  (0.10455473305642372, 97.75),\n",
       "  (0.1154905776631087, 97.62),\n",
       "  (0.11325143051078194, 97.62),\n",
       "  (0.1120749673319282, 97.8),\n",
       "  (0.10938332327083918, 97.77),\n",
       "  (0.11793999000493204, 97.68),\n",
       "  (0.11256278902188642, 97.54),\n",
       "  (0.11160648271258687, 97.72),\n",
       "  (0.1098896583424299, 97.69),\n",
       "  (0.10779916214654223, 97.78),\n",
       "  (0.1075398959040409, 97.9),\n",
       "  (0.11529764235199545, 97.61),\n",
       "  (0.11910796161658946, 97.67),\n",
       "  (0.11583541123731411, 97.58),\n",
       "  (0.11778072707324755, 97.73),\n",
       "  (0.11203111020641518, 97.63),\n",
       "  (0.10870000874513935, 97.76),\n",
       "  (0.11887393789893831, 97.65),\n",
       "  (0.11728080734550021, 97.63),\n",
       "  (0.11808283130528871, 97.74),\n",
       "  (0.1221494683651952, 97.68),\n",
       "  (0.11695446927525335, 97.78),\n",
       "  (0.11955317313751439, 97.65),\n",
       "  (0.10994797893711365, 97.74),\n",
       "  (0.11634095632757525, 97.58),\n",
       "  (0.1215176167305748, 97.66),\n",
       "  (0.12335986399538815, 97.72),\n",
       "  (0.11888589503641706, 97.74),\n",
       "  (0.12574015408391134, 97.58),\n",
       "  (0.11854143270397326, 97.78),\n",
       "  (0.12324462013808661, 97.68),\n",
       "  (0.12634280315401847, 97.62),\n",
       "  (0.11857011262249434, 97.67),\n",
       "  (0.12962398418734666, 97.61),\n",
       "  (0.11471133378001395, 97.76),\n",
       "  (0.12271519346267451, 97.77),\n",
       "  (0.12618620178195414, 97.87),\n",
       "  (0.1155337170102168, 97.81),\n",
       "  (0.13135704531776718, 97.64),\n",
       "  (0.12934890018845327, 97.75),\n",
       "  (0.12064513360126584, 97.7),\n",
       "  (0.11980782514884486, 97.81),\n",
       "  (0.12444607675373555, 97.74),\n",
       "  (0.11867093442727637, 97.75),\n",
       "  (0.11986995579048526, 97.69),\n",
       "  (0.12408657363200327, 97.64),\n",
       "  (0.1253539685181342, 97.79),\n",
       "  (0.11782395550079819, 97.73),\n",
       "  (0.12921533036779145, 97.7),\n",
       "  (0.11589933347871993, 97.78),\n",
       "  (0.11702724192358437, 97.81),\n",
       "  (0.11930406384707312, 97.76),\n",
       "  (0.11915705031885009, 97.72),\n",
       "  (0.12757412770748489, 97.65),\n",
       "  (0.12860118528082093, 97.8),\n",
       "  (0.12037742506012146, 97.77),\n",
       "  (0.13318033745750144, 97.85),\n",
       "  (0.1360315656781022, 97.58),\n",
       "  (0.1271627856791776, 97.74),\n",
       "  (0.12507266276272713, 97.78),\n",
       "  (0.12246236595547526, 97.73),\n",
       "  (0.12562710284681525, 97.7),\n",
       "  (0.13438424798007037, 97.7),\n",
       "  (0.14167380257255283, 97.61),\n",
       "  (0.1404816745838383, 97.57),\n",
       "  (0.1332521417080541, 97.63),\n",
       "  (0.13804225838343265, 97.67),\n",
       "  (0.13209426605274785, 97.76),\n",
       "  (0.13664100094856985, 97.61),\n",
       "  (0.13894659031249465, 97.7),\n",
       "  (0.1280156240967277, 97.82),\n",
       "  (0.1496769678648445, 97.38),\n",
       "  (0.14014719653940555, 97.53),\n",
       "  (0.12887745409860799, 97.88),\n",
       "  (0.13039747419213418, 97.8),\n",
       "  (0.13923868448996218, 97.59),\n",
       "  (0.12820167327588425, 97.79),\n",
       "  (0.13283650213912623, 97.72),\n",
       "  (0.13638321825210006, 97.58),\n",
       "  (0.14116602277219645, 97.65),\n",
       "  (0.12883118085698078, 97.92),\n",
       "  (0.13549727482610033, 97.74),\n",
       "  (0.14294678781082912, 97.65),\n",
       "  (0.12709092302547506, 97.81),\n",
       "  (0.12472813254703506, 97.79),\n",
       "  (0.12987712485370576, 97.91),\n",
       "  (0.13734713534994372, 97.56),\n",
       "  (0.13564904440068348, 97.66),\n",
       "  (0.13664543165714568, 97.7),\n",
       "  (0.13918894119438555, 97.58),\n",
       "  (0.13785025181580932, 97.72),\n",
       "  (0.1350951291642741, 97.8),\n",
       "  (0.13084190746862878, 97.74),\n",
       "  (0.12471783997090534, 97.74),\n",
       "  (0.13133527699530823, 97.71),\n",
       "  (0.1362533184353706, 97.68),\n",
       "  (0.1400756139289162, 97.78),\n",
       "  (0.12564582681831526, 97.86),\n",
       "  (0.1291608512589286, 97.76),\n",
       "  (0.13607614868567253, 97.81),\n",
       "  (0.1300288150706794, 97.87),\n",
       "  (0.1381440250443702, 97.72),\n",
       "  (0.13806854518852196, 97.81),\n",
       "  (0.13740616682653561, 97.68),\n",
       "  (0.13238368079578358, 97.77),\n",
       "  (0.14541695943669766, 97.63),\n",
       "  (0.1454750789188889, 97.71),\n",
       "  (0.14547749085091055, 97.71),\n",
       "  (0.14402686815007182, 97.66),\n",
       "  (0.13670348517449601, 97.7),\n",
       "  (0.14205850289279479, 97.74),\n",
       "  (0.1533606016666472, 97.67),\n",
       "  (0.14062040575446919, 97.83),\n",
       "  (0.14555305777220345, 97.61),\n",
       "  (0.1430292350890115, 97.64),\n",
       "  (0.14012620375703264, 97.63),\n",
       "  (0.1397573044825891, 97.72),\n",
       "  (0.14338144334480385, 97.69),\n",
       "  (0.1342277020968788, 97.64),\n",
       "  (0.1342185455064435, 97.75),\n",
       "  (0.13848592050572625, 97.79),\n",
       "  (0.15031241474387425, 97.63),\n",
       "  (0.14975307978770944, 97.67),\n",
       "  (0.1362493006054381, 97.77),\n",
       "  (0.1444038284840215, 97.68),\n",
       "  (0.14087102973873333, 97.73),\n",
       "  (0.14099608908316294, 97.86),\n",
       "  (0.13881134005091444, 97.72),\n",
       "  (0.12815128864345315, 97.91),\n",
       "  (0.14902906283591802, 97.64),\n",
       "  (0.145356124304088, 97.58),\n",
       "  (0.14958515478808912, 97.59),\n",
       "  (0.14288710248119896, 97.69),\n",
       "  (0.14398487178810465, 97.59),\n",
       "  (0.1513954318793505, 97.68),\n",
       "  (0.14586424021168495, 97.81),\n",
       "  (0.14723109725299618, 97.71),\n",
       "  (0.13315615286523536, 97.82),\n",
       "  (0.1511449053506156, 97.6),\n",
       "  (0.15975223226832677, 97.51)]}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
